<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta charset="utf-8" />
  <title>Optimizing Approximate Membership Metadata for Triple Pattern Fragments</title>
  <link rel="stylesheet" media="screen" href="styles/screen.css" />
  <link rel="stylesheet" media="print"  href="styles/print.css" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  
</head>
<body prefix="rdf: http://www.w3.org/1999/02/22-rdf-syntax-ns# rdfs: http://www.w3.org/2000/01/rdf-schema# owl: http://www.w3.org/2002/07/owl# xsd: http://www.w3.org/2001/XMLSchema# dcterms: http://purl.org/dc/terms/ dctypes: http://purl.org/dc/dcmitype/ foaf: http://xmlns.com/foaf/0.1/ v: http://www.w3.org/2006/vcard/ns# pimspace: http://www.w3.org/ns/pim/space# cc: https://creativecommons.org/ns# skos: http://www.w3.org/2004/02/skos/core# prov: http://www.w3.org/ns/prov# qb: http://purl.org/linked-data/cube# schema: http://schema.org/ void: http://rdfs.org/ns/void# rsa: http://www.w3.org/ns/auth/rsa# cert: http://www.w3.org/ns/auth/cert# cal: http://www.w3.org/2002/12/cal/ical# wgs: http://www.w3.org/2003/01/geo/wgs84_pos# org: http://www.w3.org/ns/org# biblio: http://purl.org/net/biblio# bibo: http://purl.org/ontology/bibo/ book: http://purl.org/NET/book/vocab# ov: http://open.vocab.org/terms/ sioc: http://rdfs.org/sioc/ns# doap: http://usefulinc.com/ns/doap# dbr: http://dbpedia.org/resource/ dbp: http://dbpedia.org/property/ sio: http://semanticscience.org/resource/ opmw: http://www.opmw.org/ontology/ deo: http://purl.org/spar/deo/ doco: http://purl.org/spar/doco/ cito: http://purl.org/spar/cito/ fabio: http://purl.org/spar/fabio/ oa: http://www.w3.org/ns/oa# as: https://www.w3.org/ns/activitystreams# ldp: http://www.w3.org/ns/ldp# solid: http://www.w3.org/ns/solid/terms# acl: http://www.w3.org/ns/auth/acl# dio: https://w3id.org/dio# as: https://www.w3.org/ns/activitystreams# oa: http://www.w3.org/ns/oa# ldp: http://www.w3.org/ns/ldp#" typeof="schema:CreativeWork sioc:Post prov:Entity">
  <header>
  <h1 id="optimizing-approximate-membership-metadata-for-triple-pattern-fragments">Optimizing Approximate Membership Metadata for Triple Pattern Fragments</h1>

  <ul id="authors">
    <li><a href="http://www.example.org/" typeof="http://xmlns.com/foaf/0.1/Person" resource="http://www.example.org/#me">John Doe</a></li>
  </ul>

  <ul id="affiliations">
    <li id="idlab">IDLab,
          Department of Electronics and Information Systems,
          Ghent University – imec</li>
  </ul>

  <section id="abstract">
    <h2>Abstract</h2>
    <!-- Context      -->
    <p>Various Linked Data Fragments (LDF) exist for exposing Linked Data on the Web.
The Triple Pattern Fragments (TPF) interface is a type of LDF that significantly lowers server-cost
by moving a large portion of the query effort client-side.
<!-- Need         -->
In previous work, Approximate Membership Functions (AMF) were added to TPF as metadata,
with the purpose of reducing the number of membership subqueries by pre-filtering potential results client-side.
Even though this lead to a reduction of HTTP requests,
the need for lower query execution times has not been met.
<!-- Task         -->
In order to effectively reduce query execution times,
we investigate several unexplored aspects regarding AMF metadata on TPF interfaces.
<!-- Object       -->
In this article, we introduce and extensively evaluate alternative approaches
for exposing (server-side) and consuming (client-side) AMF metadata
to reach lower query execution times while keeping server cost sufficiently low.
<!-- Findings     -->
Our results show that our alternative client-side algorithms significantly reduce
the number of HTTP requests and query execution times
without significantly increasing server load.
Furthermore, we conclude that server-side caching and (partial) AMF pre-computation is essential,
and offer guidelines on how AMF metadata should be configured on the server.
<!-- Conclusion   -->
Our work shows that TPF in combination with AMF metadata is feasible for data publishers,
and has significant benefits for client-side query engines.
<!-- Perspectives --></p>

  </section>

</header>

<main>
  <!-- Add sections by specifying their file name, excluding the '.md' suffix. -->
  <section id="introduction">
    <h2>Introduction</h2>

    <p>In the past years there has been a rise in popularity for non-SPARQL solutions to publish linked data.
One of the more prominent new interfaces is the <span property="schema:citation http://purl.org/spar/cito/cites" resource="https://dx.doi.org/10.1016/j.websem.2016.03.003"><a href="http://linkeddatafragments.org/publications/jws2016.pdf">Triple Pattern Fragments (TPF) interface</a></span> <span class="references">[<a href="#ref-1">1</a>]</span>.
This data access interface is situated somewhere between data dumps and SPARQL interfaces in complexity.
Many extensions and variants have been developed already, such as <a property="schema:citation http://purl.org/spar/cito/cites" href="http://rubensworks.net/raw/publications/2017/vtpf.pdf">versioning</a> <span class="references">[<a href="#ref-2">2</a>]</span>
or new <a property="schema:citation http://purl.org/spar/cito/cites" href="http://linkeddatafragments.org/publications/eswc2015.pdf">query algorithms</a> <span class="references">[<a href="#ref-3">3</a>]</span>.</p>

    <p>Many of these variants work by adding additional metadata to either the server requests or responses.
These can provide more fine-grained details than can seen by just looking at the data returned.
Additionally, adding extra metadata doesn’t break existing solutions:
older solutions will just ignore the additional metadata
and still do their work based on the rest that was provided.</p>

    <p>One of these variants was designed by Vander Sande et al.
They tested the effect of generating Approximate Membership Filters (AMFs) <span class="references">[<a href="#ref-4">4</a>]</span> 
for certain triple patterns and returning that as metadata in the TPF response.
In this paper we are going to research how the ideas presented in that paper
can be extended and made more applicable to more general cases.</p>

    <p>For this we made use of the <a property="schema:citation http://purl.org/spar/cito/cites" href="https://comunica.github.io/Article-ISWC2018-Resource/">Comunica framework</a> <span class="references">[<a href="#ref-5">5</a>]</span>,
which is a modular meta query engine.
Due to its modular nature it is perfect for easily comparing the effects of adding and removing multiple features:
those specific modules simply have to be enabled or disabled when running the corresponding tests.
This makes it much easier for us to do extensive evaluations as can be seen in <a href="#evaluation">Section 6</a>.
Additionally, Comunica already supports full TPF support out of the box,
meaning our AMF additions could be added as separate modules to the already existing framework.</p>

    <p>We also developed several tools helping in the evaluation automation.
Since a Comunica deployment is fully defined by its configuration file,
we made a system that generates those files for a required test setup
and automatically run tests over the corresponding Comunica implementation.
This allows us to be quite flexible and extensive in our evaluations.</p>

    <p>In the next section we cover the related work pertaining to this paper.
After that, we go over the problem statement in <a href="#problem-statement">Section 3</a>
followed by our suggested solution in <a href="#solution">Section 4</a>.
Our actual implementation is described in <a href="#implementation">Section 5</a>,
together with all our evaluations in <a href="#evaluation">Section 6</a>.
We finish with our conclusions in <a href="#conclusions">Section 7</a>.</p>
  </section>

  <section id="related-work">
    <h2>Related Work</h2>

    <p>In this section we cover the relevant existing research relating to our work.
The three main parts include Linked Data Fragments and specifically Triple Pattern Fragments,
which this work is an extension of,
Approximate Membership Metadata,
which is the core part of our extension,
and Comunica,
which is the framework we made our extension in.</p>

    <h3 id="related-work-ldf">Linked Data Fragments</h3>

    <p>As mentioned before, there exist many possible ways to publish linked data.
All of these interfaces can be described in terms of <span property="schema:citation http://purl.org/spar/cito/cites" resource="https://dx.doi.org/10.1016/j.websem.2016.03.003"><a href="http://linkeddatafragments.org/publications/jws2016.pdf">Linked Data Fragments (LDF)</a></span> <span class="references">[<a href="#ref-1">1</a>]</span>.
LDF provides a way to differentiate the different interfaces.</p>

    <p>The same paper also introduced a new interface, being Triple Pattern Fragments (TPF).
The idea was to provide an alternative in the middle between data dumps (high client load, not expressive) 
and SPARQL endpoints (high server load, extremely expressive)
by allowing users to only query the server with a single triple pattern at a time,
instead of full SPARQL queries,
thus forcing clients to perform the pattern joins client-side.</p>

    <p>For this, the default implementation makes use of a greedy algorithm,
always choosing one pattern based on local optima
and recursively applying its resulting bindings to the remaining patterns.
This unfortunately has the side effect of sometimes producing quite inefficient query paths.
Combined with the fact that TPF returns it results in a paginated fashion,
this causes the biggest bottleneck for TPF to be the number of HTTP requests required to solve queries.
Several additions have already been made to the default TPF implementation
in an attempt to reduce the number of those requests,
such as new <a href="cite: cites tpfoptimization, acosta_iswc_2015">query algorithms</a>,
and <a href="cite: brtpf">restricting the request patterns</a>.
Each of those with their own advantages and disadcantages.</p>

    <h3 id="related-work-amf">Approximate Membership Metadata</h3>

    <p>It has been shown that the TPF approach produces a large number of so-called <em>membership</em> requests <span class="references">[<a href="#ref-4">4</a>]</span>.
These are requests for triple patterns <em>without variables</em>, i.e., for checking if a certain triple is present in a dataset.
This was illustrated with queries from the WatDiv <span class="references">[<a href="#ref-6">6</a>]</span> benchmark,
consisting of several types of queries, namely linear (L), star (S), snowflake-shaped (F) and complex (C).
Of the 20 queries, two (L2, L4) required 50% membership requests,
one (F3) required 73%, and 4 (S5, F5, C1, C2) required more than 95%.
More than 1 in 3 queries are thus significantly impacted by the number of membership requests,
which indicates that optimizing membership queries can have a positive effect on query evaluation.</p>

    <p>Following the declarative basis of TPF for including metadata into server requests to help the client improve query evalation,
an approach was introduced to add approximate membership metadata to reduce the number of membership requests to the server <span class="references">[<a href="#ref-4">4</a>]</span>.
This metadata describes <em>Approximate Membership Functions</em> (AMF),
which are functions that enable fast membership tests with a certain chance on false positives.
The authors compared two AMF implementations,
namely <em>Bloom filters</em> <span class="references">[<a href="#ref-7">7</a>]</span> and <em>Golomb-coded sets</em> (GCS) <span class="references">[<a href="#ref-8">8</a>]</span>.
Both approaches guarantee a 100% recall, but not a 100% precision.
There is a trade-off between the size of the function, and its precision.
Client-side query engines can detect this AMF metadata,
and use it test the membership of triples.
Due to the &lt;100% precision, clients can only filter out true negatives based on AMFs,
so for testing true positives, an HTTP request will still need to be sent to the server.
The results of this work show that there is a significant decrease in the number of HTTP requests when AMFs are used,
at the cost of only a small increase in server load.
Even though the <em>number of HTTP requests is lower</em>, the <em>total execution time is higher</em> for most queries,
because of the long server delays when generating AMFs.</p>

    <p class="todo">Briefly compare Bloom and GCS?</p>

    <h3 id="related-work-comunica">Comunica</h3>

    <p><a property="schema:citation http://purl.org/spar/cito/cites" href="https://comunica.github.io/Article-ISWC2018-Resource/">Comunica</a> <span class="references">[<a href="#ref-5">5</a>]</span> is a meta query engine, designed to ease the querying of heterogeneous interfaces
with multiple possible local query solutions.
Its modular architecture allows developers to easily add or remove features.
This was quite useful for us in this work when running evaluations
as it allowed us to test out our additions compared to the original
without actually needing multiple implementations.</p>

    <p>There already are many existing modules for Comunica.
The initial components were designed so that it could be a replacement for the previous existing TPF client.
This has the additional benefit of providing a universal way to add extension to the TPF client,
instead of having them spread out over multiple branches and incompatible repositories,
as is currently the case.</p>

    <p>Comunica uses semantic configuration files to define which modules are included in a single instance.
It then uses <a property="schema:citation http://purl.org/spar/cito/cites" href="http://componentsjs.readthedocs.io/en/latest/">Components.js</a> <span class="references">[<a href="#ref-9">9</a>]</span>, a semantic dependency injection framework,
to link the different independent modules together.
These separate configuration files can then later on be reused to reproduce our evaluation results,
our build further on them.</p>

  </section>

  <section id="problem-statement">
    <h2>Problem Statement</h2>

    <p>Certain effects of using AMF metadata to improve query performance in the context of TPF were previously investigated <span class="references">[<a href="#ref-4">4</a>]</span>.
The authors mainly focused on comparing two different AMF implementations with each other,
and their effects on query execution time.
This work has introduced a number of new follow-up questions,
and offers several points for improvement.
We list these as research questions for our work, and defined hypotheses for each of them:</p>

    <ol>
      <li id="question-combine"><strong>Can query evaluation be improved by <em>combining AMFs</em> client-side?</strong>
<br />
Ealier work focused on using AMF metadata to test the membership of fully materialized triples,
while there is potential for exploiting this for other types of patterns in the query as well,
e.g., by combining multiple AMFs.
<br />
<strong>Hypotheses:</strong>
        <ol>
          <li id="hypo-combine-1">By combining AMFs client-side at BGP-level, query execution is faster compared to not using AMFs.</li>
          <li id="hypo-combine-2">By combining AMFs client-side at BGP-level, query execution is faster compared to using AMFs at triple-level.</li>
          <li id="hypo-combine-3">Using AMFs at both BGP <em>and</em> triple-level is not faster w.r.t. query execution compared to only using AMFs at BGP-level.</li>
        </ol>
      </li>
      <li id="question-cache"><strong>What query execution speedup does caching of HTTP requests and AMFs provide?</strong>
<br />
As the authors of the earlier work on AMF suggest that caching of AMFs
can reduce server delays and improve overall query evaluation,
we will investigate the impact of caching AMFs and all HTTP requests in general.
<br />
<strong>Hypotheses:</strong>
        <ol>
          <li id="hypo-cache-1">Caching all HTTP requests reduces query evaluation times more than caching only AMFs.</li>
          <li id="hypo-cache-2">Caching AMFs server-side when an HTTP cache is active has no effect on query evaluation times.</li>
          <li id="hypo-cache-3">Without HTTP caching, AMF-aware query evaluation is slower than non-AMF query evaluation.</li>
          <li id="hypo-cache-4">With HTTP caching, AMF-aware query evaluation is faster than non-AMF query evaluation.</li>
          <li id="hypo-cache-5">Query evaluation with a cold cache is significantly slower than query evaluation with a warm cache.</li>
          <li id="hypo-cache-6">With a warm cache, Bloom filters achieve lower query evaluation times compared to GCS.</li>
        </ol>
      </li>
      <li id="question-dynamic-restriction"><strong>To what extent can TPF server load be reduced by <em>dynamically restricting</em> AMF generation?</strong>
<br />
Earlier work introduced AMF as a feature that was always enabled.
However, some specific AMFs may be too expensive for servers to calculate on-the-fly.
As such, it may be beneficial to only <em>dynamically enable</em> AMFs under specific circumstances,
e.g., by only allowing AMFs to be requested for queries with result count lower than a certain threshold.
<br />
<strong>Hypotheses:</strong>
        <ol>
          <li id="hypo-dynamic-restriction-1">Lowering the threshold increases client-side query execution time when AMFs are cached.</li>
          <li id="hypo-dynamic-restriction-2">Lowering the threshold reduces server load when AMFs are not cached.</li>
          <li id="hypo-dynamic-restriction-3">Lowering the threshold does not impact server load when AMFs are cached.</li>
        </ol>
      </li>
      <li id="question-bandwidth"><strong>What impact does the HTTP bandwidth have on client-side performance with AMFs?</strong>
<br />
Experiments in earlier work on AMF were based on limited HTTP bandwidth to a realistic 1Mbps.
However, there is still an open question as to what extent different rates have an impact on the importance of AMF.
<br />
<strong>Hypotheses:</strong>
        <ol>
          <li id="hypo-bandwidth-1">HTTP bandwith has a higher impact on non-AMF usage than triple-level AMF usage.</li>
          <li id="hypo-bandwidth-2">HTTP bandwith has a higher impact on triple-level AMF usage than BGP-level AMF usage.</li>
        </ol>
      </li>
      <li id="question-inband"><strong>Can query throughput be improved by adding AMF metadata <em>in-band</em> with the TPF HTTP responses?</strong>
<br />
In previous work, AMF metadata was hidden behind a link that should be followed by the client to retrieve it,
which requires an additional HTTP request.
This opens the question as to whether including AMF metadata directly <em>in-band</em>
with the TPF HTTP responses could improve query performance.
<br />
<strong>Hypotheses:</strong>
        <ol>
          <li id="hypo-inband-1">Including AMF metadata in-band reduces client-side query execution time.</li>
          <li id="hypo-inband-2">Including AMF metadata in-band reduces the total required number of HTTP requests.</li>
        </ol>
      </li>
      <li id="question-probabilities"><strong>Which AMF <em>false-positive probabilities</em> achieve the best client-side query performance?</strong>
<br />
Based on the results the previous authors have suggested that additional experimentation is needed with regards
to lower <em>AMF false-positive probabilities</em>, as higher probabilities do not have a significant effect on query performance.
<br />
<strong>Hypotheses:</strong>
        <ol>
          <li id="hypo-probabilities-1">The lower the false-positive probability, the faster the client-side query execution.</li>
        </ol>
      </li>
    </ol>

    <p>To come up with an answer to these research questions,
their hypotheses will be tested in <a href="#evaluation">Section 6</a> based on our experimental results.</p>
  </section>

  <section id="solution">
    <h2>Solution</h2>

    <p class="todo">Describe how the AMF stuff is used and how the algorithm looks like.
Focus on the 2 triple algorithms and heuristic.</p>

    <p>To make use of AMFs for more efficient TPF querying,
there are two places where changes need to be made:
the server needs to generate and expose the new metadata,
and the client needs to incorporate it in the query algorithm.</p>

    <h3 id="server-side-metadata-generation">Server-side metadata generation</h3>
    <p>The server-side implementation is mostly based on the implementation by Vander Sande et al. <span class="references">[<a href="#ref-4">4</a>]</span>
Some additions were made though, such as when an AMF gets generated and how they get returned.</p>

    <p>The first change that was made is for which patterns AMFs get generated.
Previously this was only for patterns with a single variable,
but we made the server more flexible in that regard:
now we allow the server to generate AMFs for any patterns,
based on limitations given in the server config file.
The two available limitations are variable count and triple count:
AMFs will be generated for each pattern of which the number of variables
and/or the total number of results is at most the given values.
This allows the client to use the AMF metadata in more situations than before.</p>

    <p>A second addition was the option of allowing AMFs to be sent out-of-band.
This means that the server only returns a URL to where the actual AMF result can be found.
The advantage there is that this reduces both the response size and the effort needed to generate an AMF
in cases where it is not required.
It is also possible to combine this with the previous change,
i.e., have two sets of limits: if the pattern exceeds the first limit only out-of-band AMF becomes available,
and after the second one there is no AMF option at all.
This allows servers to provide metadata for larger triples,
but still prevents the more extreme edge cases from slowing everything down.</p>

    <p>Finally we also added an internal cache:
all generated AMFs are stored in an LRU cache,
meaning the more popular pattern metadata gets stored in memory.
This greatly cuts down on the time needed to actually generate that metadata.</p>

    <h3 id="client-side-query-algorithm">Client-side query algorithm</h3>
    <p>The main changes in this paper are how we made us of the AMF metadata to improve the client-side querying.
For this we developed two new query algorithms that use the metadata on BGP level,
the results of which are shown in <a href="#evaluation">Section 6</a>.</p>

    <p>In the original AMF algorithm <span class="references">[<a href="#ref-4">4</a>]</span>,
bindings only got filtered when a pattern would be fully bound.
The main idea behind our new algorithm is to already do this filtering much sooner in the querying process.
The added advantage is that fewer bindings have to be sent to the server,
at the cost of generating more filters.</p>

    <p><a href="#tpf">Listing 1</a> shows how the original TPF algorithm works.
For the specific details we refer the reader to the <span property="schema:citation http://purl.org/spar/cito/cites" resource="https://dx.doi.org/10.1016/j.websem.2016.03.003"><a href="http://linkeddatafragments.org/publications/jws2016.pdf">original paper</a></span> <span class="references">[<a href="#ref-1">1</a>]</span>.
Our additions to the algorithm can be found in <a href="#amf-bgp-pseudo">Listing 2</a>.
The code here is quite simplified,
more specific details on how we added this to Comunica can be found in <a href="#solution">Section 4</a>.</p>

    <figure id="tpf" class="listing">
<pre><code>function solve (patterns) {
</code><code>  const smallestIdx = /* find i where patterns[i].totalItems is the smallest */
</code><code>  const bindingsStream = getBindings(patterns[smallestIdx]);
</code><code>  const remainingPatterns = patterns.remove(smallestIdx);
</code><code>  if (remainingPatterns.isEmpty())
</code><code>    return bindingsStream;
</code><code>
</code><code>  const resultStream = /* empty stream */
</code><code>  for (let bindings of bindingsStream) {
</code><code>    const mappedPatterns = applyBindings(remainingPatterns, bindings);
</code><code>    solve(mappedPatterns).pipe(resultStream);
</code><code>  }
</code><code>  return resultStream;
</code><code>}</code></pre>
<figcaption>
        <p><span class="label">Listing 1:</span> Original TPF algorithm. More details can be found in the <span property="schema:citation http://purl.org/spar/cito/cites" resource="https://dx.doi.org/10.1016/j.websem.2016.03.003"><a href="http://linkeddatafragments.org/publications/jws2016.pdf">original paper</a></span> <span class="references">[<a href="#ref-1">1</a>]</span>.</p>
      </figcaption>
</figure>

    <figure id="amf-bgp-pseudo" class="listing">
<pre><code>function solve (patterns) {
</code><code>  const smallestIdx = /* find i where patterns[i].totalItems is the smallest */
</code><code>  const bindingsStream = getBindings(patterns[smallestIdx]);
</code><code>  const remainingPatterns = patterns.remove(smallestIdx);
</code><code>  if (remainingPatterns.isEmpty())
</code><code>    return bindingsStream;
</code><code>
</code><code>  const resultStream = /* empty stream */
</code><code>  for (let bindings of bindingsStream) {
</code><code>
</code><code>    // ----- AMF -----
</code><code>    let valid = true;
</code><code>    for (let pattern of mappedPatterns)
</code><code>      valid = pattern.amf.check(bindings);
</code><code>    if (!valid)
</code><code>      continue;
</code><code>    // ----- AMF -----
</code><code>
</code><code>    const mappedPatterns = applyBindings(remainingPatterns, bindings);
</code><code>    solve(mappedPatterns).pipe(resultStream);
</code><code>  }
</code><code>  return resultStream;
</code><code>}</code></pre>
<figcaption>
        <p><span class="label">Listing 2:</span> Updated algorithm with AMF code.</p>
      </figcaption>
</figure>

    <p>The main idea is that all new bindings first get filtered through all applicable AMFs.
Although this is simplified in <a href="#amf-bgp-pseudo">Listing 2</a>,
only the AMFs that filter over variables that are contained in the new bindings are applied.
This also means that should the filters be provided out-of-band,
only the necessary filters will be downloaded.
In the end, the result is that many unnecessary server requests will be avoided due to the filtering,
as will be shown in <a href="#evaluation">Section 6</a>.</p>

    <h4 id="reducing-inefficient-amf-usage">Reducing inefficient AMF usage</h4>

    <p>One problem with the above solutions is that certain AMFs can get quite big.
In cases where there are not many bindings that need to be filtered,
the time it takes to download the AMF might be greater than simply not using the filter at all.</p>

    <p>For cases like this we added a heuristic that checks whether it might be a good idea to download the filter.
To handle cases like this, 
we created a heuristic that estimates both the time it would take to accept all the bindings,
and the time it would take to download an AMF for the given amount of triples.
Based on those estimates a choice gets made on whether to request the metadata or not.
Our heuristic is quite simple as will be shown later,
and serves more to indicate that there is still much potential there for future work.</p>

  </section>

  <section id="implementation">
    <h2>Implementation</h2>

    <p class="todo">There is too much overlap with the previous section, should merge or re-think how to handle probably.</p>

    <p>To implement our solution described in <a href="#solution">Section 4</a> we made use of the <a property="schema:citation http://purl.org/spar/cito/cites" href="https://comunica.github.io/Article-ISWC2018-Resource/">Comunica framework</a> <span class="references">[<a href="#ref-5">5</a>]</span>,
which already fully supports the TPF algorithm.
Its modular structure makes it ideal for us to add on to the existing implementation,
without having to change the existing code base.
Adding our features to the Comunica ecosystem caused us to create <a href="https://github.com/comunica/comunica-feature-amf" class="mandatory" data-link-text="https:/​/​github.com/​comunica/​comunica-​feature-​amf">8 new modules</a>
to integrate our new features with the framework.</p>

    <p>Since there is no modular infrastructure on the server side,
we created a <a href="https://github.com/LinkedDataFragments/Server.js/tree/feature-handlers-amf-2" class="mandatory" data-link-text="https:/​/​github.com/​LinkedDataFragments/​Server.js/​tree/​feature-​handlers-​amf-​2">new branch</a> in the repository that supports returning the required metadata.</p>

    <p class="todo">Anonymize source code links</p>

    <h3 id="integration-with-comunica">Integration with Comunica</h3>

    <p class="todo">Put Comunica description summary completely in related work and reference that?</p>

    <p>For a full overview of how Comunica works,
we refer to the resource <a property="schema:citation http://purl.org/spar/cito/cites" href="https://comunica.github.io/Article-ISWC2018-Resource/">paper</a> <span class="references">[<a href="#ref-5">5</a>]</span>.
The main idea is that an instance consists of many actors
that all fulfill a specific task.
Actors don’t communicate directly with each other:
if input is required from an actor with a different function
this gets done by a mediator in-between.
Such a mediator has a collection of actors implementing the same functionality (a bus),
and then picks one to execute the given request.</p>

    <p>For our Comunica implementation,
we added components on several levels:</p>

    <ul>
      <li>An actor to extract AMF metadata</li>
      <li>Two actors to apply Bloom and GCS membership filters to RDF data</li>
      <li>A bus module to group membership filter actors</li>
      <li>An actor implementing the original AMF algorithm <span class="references">[<a href="#ref-4">4</a>]</span></li>
      <li>Two new BGP actors, to apply two different implementations of our AMF algorithm</li>
      <li>A new SPARQL actor with a new default config that also includes these AMF actors</li>
    </ul>

    <p>All these actors can be independently to an existing Comunica framework,
depending on the needs of the user.
For the evaluations in <a href="#evaluation">Section 6</a>,
we created several config files,
enabling and disabling some of these features as required for the given test.
They could also easily be integrated into the framework,
since there already were actors to extract metadata,
or actors to handle BGPs,
these actors were simply added next to the existing ones or replaced them.</p>

    <h4 id="bgp-actor">BGP actor</h4>

    <p class="todo">Pictures could probably help here.</p>

    <p>Since the biggest change compared to the previous work is the new BGP algorithm,
we will delve deeper into the implementation of that actor.
<a href="#tpf">Listing 1</a> contains a simplified view at how the current framework handles BGP resolution in Comunica.
Since we want to make use of the modular nature of Comunica,
and not edit the existing code,
we can’t actually add our code in the existing actor.
To handle this,
we made a new BGP actor, BGP-AMF, that gets called before the original BGP actor receives the patterns.
<a href="#bgp-amf">Listing 3</a> shows a simplified version of what this actor does.</p>

    <figure id="bgp-amf" class="listing">
<pre><code>function solve (patterns) {
</code><code>  for (pattern in patterns) {
</code><code>    for (boundValue in pattern) {
</code><code>      if (!pattern.parentAMF.check(boundValue))
</code><code>        return;
</code><code>    }
</code><code>  }
</code><code>  
</code><code>  return bgpMediator.call(patterns);
</code><code>}</code></pre>
<figcaption>
        <p><span class="label">Listing 3:</span> New BGP-AMF actor.</p>
      </figcaption>
</figure>

    <p>The <code>parentAMF</code> variable seen there is the filter metadata of the pattern in the previous iteration.
This means that if the pattern was bound to a certain value in this iteration,
it still has the filter for the variable that was in that position.
In case the metadata is sent out-of-band,
the actual filter would only be downloaded at this point due to lazy programming.</p>

    <p>For the sake of brevity we will not show a code sample of the second implementation.
But the idea with that actor is to first group all filters based on the variable they are applicable to.
In case of out-of-band data, this actor would prefetch the metadata simultaneously,
helping performance.
In case the heuristic mentioned before was enabled, both these actors would also be responsible for making use of it.</p>

    <h3 id="server-metadata">Server metadata</h3>

    <p class="todo">Is there added value in describing what the metadata looks like here?</p>

  </section>

  <section id="evaluation">
    <h2>Evaluation</h2>

    <p>The goal of this section is to answer the research questions from <a href="#problem-statement">Section 3</a>.
We start by introducing a reusable benchmarking framework to achieve fully reproducible results.
Next, we present our experimental setup, followed by the presentation of our results and testing of our hypotheses.
Finally, we discuss these results to answer our research questions.</p>

    <h3 id="reusable-benchmarking-framework">Reusable Benchmarking Framework</h3>

    <p>Different Linked Data Fragments approaches as discussed in <a href="#related-work-ldf">Subsection 2.1</a>
usually require similar steps when running experiments.
Such <em>experiments require a significant amount of manual effort</em>
for setting up experiments, running them, and generating plots.
In order to avoid re-inventing the wheel again for this work, and for future works in this domain,
we developed a reusable benchmarking framework for Linked Data Fragments experiments, called <em>Comunica Bencher</em>.
This tool is based on <a href="https://www.docker.com/">Docker</a>, and allows isolated execution of experiments over different containers.
Experiment configurations are fully <em>declarative</em>, and they can exist in standalone repositories.
In order to achieve deterministic reproducibility,
a summary of all <a property="schema:citation http://purl.org/spar/cito/cites" href="https://linkedsoftwaredependencies.org/articles/describing-experiments/">used <em>software versions and their dependencies</em> in a Turtle document</a> <span class="references">[<a href="#ref-10">10</a>]</span>
will be generated after each run together with the evaluation results.
Comunica Bencher is <em>open-source</em>, and is available on GitHub.</p>

    <p class="todo">Include link to anonymized source code dump.</p>

    <p>Concretely, Comunica Bencher offers abstraction of the following <a about="#evaluation-workflow" content="Comunica Bencher evaluation workflow" href="#evaluation-workflow" property="rdfs:label" rel="cc:license" resource="https://creativecommons.org/licenses/by/4.0/">evaluation workflow</a>:</p>

    <ol id="evaluation-workflow" property="schema:hasPart" resource="#evaluation-workflow" typeof="opmw:WorkflowTemplate">
<li id="workflow-data" about="#workflow-data" typeof="opmw:WorkflowTemplateProcess" rel="opmw:isStepOfTemplate" resource="#evaluation-workflow" property="rdfs:label">
        <p>Generate a WatDiv <span class="references">[<a href="#ref-6">6</a>]</span> dataset with a given scale factor.</p>
      </li>
<li id="workflow-queries" about="#workflow-queries" typeof="opmw:WorkflowTemplateProcess" rel="opmw:isStepOfTemplate" resource="#evaluation-workflow" property="rdfs:label">
        <p>Generate the corresponding default WatDiv <a href="https://dsg.uwaterloo.ca/watdiv/basic-testing.shtml" class="mandatory" data-link-text="https:/​/​dsg.uwaterloo.ca/​watdiv/​basic-​testing.shtml">queries</a> with a given query count.</p>
      </li>
<li id="workflow-tpf-server" about="#workflow-tpf-server" typeof="opmw:WorkflowTemplateProcess" rel="opmw:isStepOfTemplate" resource="#evaluation-workflow" property="rdfs:label">
        <p>Install <a href="https://github.com/LinkedDataFragments/Server.js" class="mandatory" data-link-text="https:/​/​github.com/​LinkedDataFragments/​Server.js">the LDF server software</a> with a given configuration, implementing the <a href="https://www.hydra-cg.com/spec/latest/triple-pattern-fragments/" class="mandatory" data-link-text="https:/​/​www.hydra-​cg.com/​spec/​latest/​triple-​pattern-​fragments/​">TPF specification</a>.</p>
      </li>
<li id="workflow-cache" about="#workflow-cache" typeof="opmw:WorkflowTemplateProcess" rel="opmw:isStepOfTemplate" resource="#evaluation-workflow" property="rdfs:label">
        <p>Setup an <a href="https://www.nginx.com/" class="mandatory" data-link-text="https:/​/​www.nginx.com/​">NGINX HTTP cache</a> with a given configuration in front of the LDF server.</p>
      </li>
<li id="workflow-comunica" about="#workflow-comunica" typeof="opmw:WorkflowTemplateProcess" rel="opmw:isStepOfTemplate" resource="#evaluation-workflow" property="rdfs:label">
        <p>Install <a href="https://github.com/comunica/comunica" class="mandatory" data-link-text="https:/​/​github.com/​comunica/​comunica">the Comunica software</a> under a given configuration, implementing the <a href="https://www.w3.org/TR/sparql11-protocol">SPARQL 1.1 protocol</a>.</p>
      </li>
<li id="workflow-comunica-run" about="#workflow-comunica-run" typeof="opmw:WorkflowTemplateProcess" rel="opmw:isStepOfTemplate" resource="#evaluation-workflow" property="rdfs:label">
        <p>Execute the generated WatDiv queries a given number times on the Comunica client, after doing a warmup run, and record the execution times.</p>
      </li>
<li id="workflow-collect" about="#workflow-collect" typeof="opmw:WorkflowTemplateProcess" rel="opmw:isStepOfTemplate" resource="#evaluation-workflow" property="rdfs:label">
        <p>For each experiment, plot the execution times for all combinations and queries next to each other.</p>
      </li>
</ol>

    <h3 id="experimental-setup">Experimental Setup</h3>

    <p>Based on our LDF server and Comunica implementations that were discussed in <a href="#implementation">Section 5</a>,
we defined six experiments, corresponding to our six research questions from <a href="#problem-statement">Section 3</a>.
The declararive configuration files for running these experiments with Comunica Bencher are present on <a href="https://github.com/comunica/Experiments-AMF" class="mandatory" data-link-text="https:/​/​github.com/​comunica/​Experiments-​AMF">GitHub</a> under an open license,
and can be started from scratch by <em>executing a single command</em>.
Furthermore, all raw results and scripts for analyzing them can be found in this same repository.</p>

    <p class="todo">Anonimize link to repo</p>

    <p>All of the following experiments have several things in common, unless indicated otherwise.
First, they are all executed using WatDiv with a dataset scale of 100,
and a query count of 5 for the default query templates, leading to a total of 100 queries.
Each experiment includes a warmup phase,
and averages results over 3 separate runs.
During this warmup phase, the server caches all generated AMFs.
Furthermore, the default network delay has been configured to 1024Kbps to enforce a realistic Web bandwidth.
Finally, each experiment uses an NGINX HTTP cache,
and the client-side query timeout has been set to 5 minutes.
All experiments were executed on a 64-bit Ubuntu 14.04 machine with 128 GB of memory and a 24-core 2.40 GHz CPU.</p>

    <ol>
      <li><strong>Client-side AMF Algorithms</strong>:
 First, we compare different client-side algorithms (<em>None, Triple, BGP Simple, BGP Combined, Triple with BGP Combined</em>)
 for using AMF metadata.
 Next, we compare different constants for the BGP actor-skipping heurtistic.
 Finally, we compare the effects of exposing different AMF filter implementations (<em>Bloom, GCS</em>) server-side.</li>
      <li><strong>Caching</strong>:
 In this experiment, we evaluate the effects of caching all HTTP requests combined with caching AMF filters server-side.
 We also compare the effects of using AMF metadata client-side or not.
 Finally, we test the effects of warm and cold caches.</li>
      <li><strong>Dynamically Enabling AMF</strong>:
 In this experiment, we compare different result count thresholds (<em>0, 1.000, 10.000, 100.000, 1.000.000</em>) with each other,
 with either the server-side AMF filter cache enabled or not.
 We disable the HTTP cache and warmup phase to evaluate a cold-start.</li>
      <li><strong>HTTP Bandwidths</strong>:
 Different network bandwidths (<em>256kbps, 512kbps, 2048kbps, 4096kbps</em>) are evaluated, and their effects or different AMF algorithms (<em>None, Triple, BGP Combined</em>) are tested.</li>
      <li><strong>In-band vs. Out-of-band</strong>:
 For this experiment, we test the effects of different triple count thresholds (<em>0, 1.000, 10.000, 100.000, 1.000.000</em>) for exposing AMF metadata in-band or not.</li>
      <li><strong>False-positive Probabilities</strong>:
 In this final experiment, we compare different AMF false-positive probabilities (<em>1/4096, 1/2048, 1/1024, 1/128, 1/64, 1/8, 1/4, 1/2</em>).</li>
    </ol>

    <h3 id="results">Results</h3>

    <p>In this section, we present the results for each of our experiments separately.
We tested our hypotheses statistically by comparing means using the Kruskal-Wallis test,
and report on their p-values (<em>low values indicate non-equal means</em>).</p>

    <h4 class="display-block" id="client-side-amf-algorithms">Client-side AMF Algorithms</h4>

    <figure id="plot_client_algos">
<center>
<img src="img/experiments/client_algos/plot_no_c.svg" alt="Client-side AMF Algorithms (non-C)" class="plot_non_c" />
<img src="img/experiments/client_algos/plot_c.svg" alt="Client-side AMF Algorithms (C)" class="plot_c" />
</center>
<figcaption>
        <p><span class="label">Fig. 1:</span> Query evaluation times for the different client-side algorithms for using AMF metadata.</p>
      </figcaption>
</figure>

    <figure id="plot_skip_bgp_heuristic">
<center>
<img src="img/experiments/skip_bgp_heuristic/plot_no_c.svg" alt="Client-side AMF Algorithms with BGP skipping heuristic (non-C)" class="plot_non_c" />
<img src="img/experiments/skip_bgp_heuristic/plot_c.svg" alt="Client-side AMF Algorithms with BGP skipping heuristic (C)" class="plot_c" />
</center>
<figcaption>
        <p><span class="label">Fig. 2:</span> Query evaluation times when enabling the heuristic in the client-side combined BGP algorithm.</p>
      </figcaption>
</figure>

    <figure id="plot_client_algos_dief">
<center>
<img src="img/experiments/client_algos/dief_time.svg" alt="Diefficiency values for Client-side AMF Algorithms" class="plot_non_c" />
</center>
<figcaption>
        <p><span class="label">Fig. 3:</span> Time diefficiency metric values for the different client-side algorithms for using AMF metadata.
C3 and S7 are excluded as they produce no results.</p>
      </figcaption>
</figure>

    <p><a href="#plot_client_algos">Fig. 1</a> shows the query evaluation times for our first experiment
on the different client-side algorithms for using AMF metadata.
In line with what was shown in the first TPF AMF experiments <span class="references">[<a href="#ref-4">4</a>]</span>,
the triple-based algorithm reduces query evaluation times in only 2 of the 20 queries.
Our new BGP-based algorithms on the other hand reduce query evaluation times and outperforms the triple-based algorithm.
Only for 5 of the 20 queries, evaluation times are worse.
Our combined BGP algorithm is slightly faster than the simple BGP algorithm.
By using both the combined BGP-based and the triple-based algorithms, we can reduce evaluation times slightly further.</p>

    <p>Based on these results, we can confirm that there is <em>no statistical difference</em> between the evaluation times of the triple-based algorithm, and not using AMF metadata at all (<em>p-value: 0.9318</em>).
The simple and combined BGP algorithm are significantly faster than not using AMF metadata (<em>p-values: 0.0062, 0.0026</em>),
which confirms <a href="#hypo-combine-1">Hypothesis 1.1</a>.
Furthermore, the simple and combined BGP algorithm are significantly faster than the triple-based algorithm (<em>p-values: 0.0090, 0.0041</em>),
which confirms <a href="#hypo-combine-2">Hypothesis 1.2</a>.
Furthermore, combining our simple and combined BGP algorithm with the triple-based algorithms
has no statistically significant effect (<em>p-values: 0.9484, 0.6689</em>), which confirms <a href="#hypo-combine-3">Hypothesis 1.3</a>.</p>

    <p>In <a href="#plot_skip_bgp_heuristic">Fig. 2</a>, we show the results where we apply the heuristic
for dynamically disabling the BGP heuristic based on different parameter values.
On average, setting the request size parameter value to 2000 has the lowest average evaluation time for this experiment.
This case only achieves higher evaluation times for 1 of the 20 queries,
which is an improvement compared to not using the heuristic.
This improvement is however only small, and not statistically significant (<em>p-value: 0.1842</em>).</p>

    <p><a href="#plot_client_algos_dief">Fig. 3</a> shows the time diefficiency metric <span class="references">[<a href="#ref-11">11</a>]</span>
values for all queries over all client-side algorithms.
This metric is used to measure the continuous arrival rate of query results,
where higher values indicate faster result arrival rates.
For making comparisons possible, we scaled these values per query from 0 to 1.
The results show that querying without using AMF metadata achieves the highest diefficiency values.
This means that results start coming in sooner when AMF is not being used,
even though the time until the last result is produced is typically higher compared to when AMF <em>is</em> used.</p>

    <h4 class="display-block" id="caching">Caching</h4>

    <figure id="plot_caching">
<center>
<img src="img/experiments/caching/plot_no_c.svg" alt="Caching (non-C)" class="plot_non_c" />
<img src="img/experiments/caching/plot_c.svg" alt="Caching (C)" class="plot_c" />
</center>
<figcaption>
        <p><span class="label">Fig. 4:</span> Logarithmic query evaluation times comparing server-side HTTP and AMF caching.</p>
      </figcaption>
</figure>

    <p><a href="#plot_caching">Fig. 4</a> shows that caching either HTTP requests or AMF filters server-side has a significant positive effect on query evaluation (<em>p-value: &lt; 2.2e-16</em>).
We observe that caching HTTP requests reduces query evaluation times <em>more</em> than just caching AMF filters (<em>p-value: 0.0225</em>),
which conforms <a href="#hypo-cache-1">Hypothesis 2.1</a>.
Furthermore, there is no significant difference between query evaluation times for caching of both HTTP requests and AMF filters
compared to just caching HTTP requests (<em>p-value: 0.7694</em>), which accepts <a href="#hypo-cache-2">Hypothesis 2.2</a>.</p>

    <p>If we compare these results with the results for non-AMF-aware querying,
we see that <em>if HTTP caching is disabled</em>, query evaluation times for non-AMF-aware querying are <em>significantly lower</em> than AMF-aware approaches (<em>p-value: &lt; 2.2e-16</em>), which confirms <a href="#hypo-cache-3">Hypothesis 2.3</a>.
On the other hand, <em>if HTTP caching is enabled</em>, query evaluation times for non-AMF-aware querying are <em>significantly higher</em> than AMF-aware approaches (<em>p-value: &lt; 2.2e-16</em>), which confirms <a href="#hypo-cache-4">Hypothesis 2.4</a>.</p>

    <p class="todo"><a href="#hypo-cache-5">Hypothesis 2.5</a></p>

    <p>Finally, our results show that when our cache is warm, exposing Bloom filters instead of GCS achieves faster query evaluation times.
While there are a few outliers where GCS is two to three times slower,
the difference is only small in most cases, so we accept <a href="#hypo-cache-6">Hypothesis 2.6</a> with a low significance (<em>p-value: 0.1786</em>).</p>

    <h4 class="display-block" id="dynamically-enabling-amf">Dynamically Enabling AMF</h4>

    <figure id="plot_server_metadata_enabled_cached">
<center>
<img src="img/experiments/server_metadata_enabled/plot_cached_no_c.svg" alt="Effect of AMF result count thresholds with HTTP cache (non-C)" class="plot_non_c" />
<img src="img/experiments/server_metadata_enabled/plot_cached_c.svg" alt="Effect of AMF result count thresholds with HTTP cache (C)" class="plot_c" />
</center>
<figcaption>
        <p><span class="label">Fig. 5:</span> Query evaluation times for different AMF result count thresholds for different AMF algorithms when HTTP caching is enabled.</p>
      </figcaption>
</figure>

    <figure id="plot_server_metadata_enabled_notcached">
<center>
<img src="img/experiments/server_metadata_enabled/plot_notcached_no_c.svg" alt="Effect of AMF result count thresholds without HTTP cache (non-C)" class="plot_non_c" />
<img src="img/experiments/server_metadata_enabled/plot_notcached_c.svg" alt="Effect of AMF result count thresholds without HTTP cache (C)" class="plot_c" />
</center>
<figcaption>
        <p><span class="label">Fig. 6:</span> Query evaluation times for different AMF result count thresholds for different AMF algorithms when HTTP caching is disabled.</p>
      </figcaption>
</figure>

    <figure id="plot_threshold_serverload">
<center>
<img src="img/experiments/server_metadata_enabled/threshold_serverload.svg" alt="Server CPU usage for AMF result counts" class="plot_c" />
</center>
<figcaption>
        <p><span class="label">Fig. 7:</span> Average server CPU usage for different AMF result count thresholds when caching is enabled and disabled.</p>
      </figcaption>
</figure>

    <p><a href="#plot_server_metadata_enabled_cached">Fig. 5</a> shows lower AMF result count thresholds
lead to higher query evaluation times when HTTP caching is enabled (<em>p-value: 2.11e-07</em>),
which confirms <a href="#hypo-dynamic-restriction-1">Hypothesis 3.1</a>.
<a href="#plot_server_metadata_enabled_notcached">Fig. 6</a> shows that AMF result count thresholds
also have an impact on query evaluation times when HTTP caching is disabled (<em>p-value: 0.0005</em>),
but it does not necessarily lower it. For this experiment, setting the threshold to 10K leads to the lowest overall query evaluation times.</p>

    <p><a href="#plot_threshold_serverload">Fig. 7</a> shows that lower AMF result count thresholds lead to lower server loads
when HTTP caching is disabled (<em>p-value: 0.0326</em>), which confirms <a href="#hypo-dynamic-restriction-2">Hypothesis 3.2</a>.
On the other hand, if HTTP caching is enabled,
there is no correlation between AMF result count threshold and server CPU usage (<em>p-value: 0.4577</em>), which confirms <a href="#hypo-dynamic-restriction-3">Hypothesis 3.3</a>).</p>

    <h4 class="display-block" id="http-bandwidths">HTTP Bandwidths</h4>

    <figure id="plot_delay_none">
<center>
<img src="img/experiments/delay/plot_none_no_c.svg" alt="Effect of HTTP bandwidth on non-AMF (non-C)" class="plot_non_c" />
<img src="img/experiments/delay/plot_none_c.svg" alt="Effect of HTTP bandwidth on non-AMF (C)" class="plot_c" />
</center>
<figcaption>
        <p><span class="label">Fig. 8:</span> Query evaluation times for different HTTP bandwidths when AMF is not used.</p>
      </figcaption>
</figure>

    <figure id="plot_delay_triple">
<center>
<img src="img/experiments/delay/plot_triple_no_c.svg" alt="Effect of HTTP bandwidth on triple AMF (non-C)" class="plot_non_c" />
<img src="img/experiments/delay/plot_triple_c.svg" alt="Effect of HTTP bandwidth on triple AMF (C)" class="plot_c" />
</center>
<figcaption>
        <p><span class="label">Fig. 9:</span> Query evaluation times for different HTTP bandwidths for the triple-based AMF algorithm.</p>
      </figcaption>
</figure>

    <figure id="plot_delay_bgp">
<center>
<img src="img/experiments/delay/plot_bgp_no_c.svg" alt="Effect of HTTP bandwidth on BGP AMF (non-C)" class="plot_non_c" />
<img src="img/experiments/delay/plot_bgp_c.svg" alt="Effect of HTTP bandwidth on BGP AMF (C)" class="plot_c" />
</center>
<figcaption>
        <p><span class="label">Fig. 10:</span> Query evaluation times for different HTTP bandwidths for the BGP-based AMF algorithm.</p>
      </figcaption>
</figure>

    <p><a href="#plot_delay_none">Fig. 8</a>, <a href="#plot_delay_triple">Fig. 9</a> and <a href="#plot_delay_bgp">Fig. 10</a> show the effects of different HTTP bandwidths
on query evaluation times over different algorithms.
We observe that when not using AMF, or using the triple-level AMF algorithm,
lower bandwidths lead to higher query evaluation times, but higher bandwidths do not keep reducing evaluation times.
The BGP-level AMF algorithm on the other hand keeps becoming faster with increased HTTP bandwidths.
Statistically, we don’t measure any significant impact of HTTP bandwidth on both non-AMF usage and triple-level AMF usage (<em>p-values: 0.2905, 0.2306</em>), which rejects <a href="#hypo-bandwidth-1">Hypothesis 4.1</a>.
For BGP-level AMF, we measure a significant impact (<em>p-value: 0.0028</em>), which accepts <a href="#hypo-bandwidth-2">Hypothesis 4.2</a>.</p>

    <h4 class="display-block" id="in-band-vs-out-of-band">In-band vs. Out-of-band</h4>

    <figure id="plot_in_vs_out_band">
<center>
<img src="img/experiments/in_vs_out_band/plot_no_c.svg" alt="In-band vs out-band (non-C)" class="plot_non_c" />
<img src="img/experiments/in_vs_out_band/plot_c.svg" alt="In-band vs out-band (C)" class="plot_c" />
</center>
<figcaption>
        <p><span class="label">Fig. 11:</span> Query evaluation times comparing out-of-band and in-band based on different AMF triple count threshold.</p>
      </figcaption>
</figure>

    <p><a href="#plot_in_vs_out_band">Fig. 11</a> shows query evaluation times for different possibilities for including AMF metadata in-band or out-of-band.
Statistically, there is no significant different difference between these combinations (<em>p-value: 0.7323</em>),
which rejects <a href="#hypo-inband-1">Hypothesis 5.1</a>.</p>

    <p>Furthermore, when analyzing the HTTP logs, we observe only a very small decrease (&lt;1%) in the difference in number of requests.
As this difference is insignificant (<em>p-value: 0.406</em>), we can reject <a href="#hypo-inband-2">Hypothesis 5.2</a>
in which we expected the number of HTTP requests to significantly decrease when we moved AMF metadata in-band.</p>

    <h4 class="display-block" id="false-positive-probabilities">False-positive Probabilities</h4>

    <figure id="plot_probabilities">
<center>
<img src="img/experiments/probabilities/plot_no_c.svg" alt="In-band vs out-band (non-C)" class="plot_non_c" />
<img src="img/experiments/probabilities/plot_c.svg" alt="In-band vs out-band (C)" class="plot_c" />
</center>
<figcaption>
        <p><span class="label">Fig. 12:</span> Query evaluation times comparing different false-positive probabilities for AMFs that are generated server-side.</p>
      </figcaption>
</figure>

    <p><a href="#plot_probabilities">Fig. 12</a> shows that different false-positive probabilities have some impact on query evaluation times.
This impact has however only has a weak significance (<em>p-value: 0.184</em>).
This means that we can reject <a href="#hypo-probabilities-1">Hypothesis 6.1</a>
in which we expected that lower false-positive probabilities lead to lower query evaluation times.
On average, a false-positive probability of 1/64 leads to the lowest overall query evaluation times for this experiment.</p>

    <h3 id="discussion">Discussion</h3>

    <h4 id="bgp-based-algorithms-improve-query-efficiency">BGP-based algorithms improve query efficiency</h4>

    <p>Results show that our new client-side BGP-based algorithms that use AMF metadata
significantly reduce query evaluation times  (<em><a href="#question-combine">Research Question 1</a></em>).
However, the are a few outliers where our new algorithms perform <em>worse</em> than the triple-based algorithm.
Our results have shown that a heuristic that can decide whether or not to use the BGP-based algorithm can solve this problem,
but further research is needed to come up with a more general heuristic that works in a variety of cases
and is not overfitted to these experiments.</p>

    <h4 id="bgp-based-algorithms-postpone-time-to-first-results">BGP-based algorithms postpone time to first results</h4>

    <p>Even though total query evaluation times for the AMF-aware algorithms are mostly lower,
the diefficiency values are typically lower, which means that results come in at a lower rate.
The reason for this can be seen when analyzing the times at which each query result arrives, as can be seen in <a href="#plot_query_times_F3">Fig. 13</a>,
but is observable for other queries as well.
This figure shows that the time-until-first-result is higher for BGP-based AMF algorithms.
This is because the BGP-based algorithms tends to use larger AMFs, which introduces a bottleneck when requesting them over HTTP.
Even though we have this overhead, the gains we get from this are typically worth it,
as results come in much faster once the AMFs have been downloaded.
This figure shows that dynamically switching between different algorithms may be interesting to investigate in future work.
Our HTTP bandwidth experiment results confirm this, and show that higher bandwidths
lead to even more performance gains for the BGP-level algorithms (<em><a href="#question-bandwidth">Research Question 4</a></em>).</p>

    <figure id="plot_query_times_F3">
<center>
<img src="img/experiments/client_algos/query_times_F3.svg" alt="Query Times for F3 over different Client-side AMF Algorithms" class="plot_non_c" />
</center>
<figcaption>
        <p><span class="label">Fig. 13:</span> Query result arrival times for query F3 for the different client-side algorithms.</p>
      </figcaption>
</figure>

    <h4 id="pre-computation-and-caching-of-amfs-is-essential">Pre-computation and caching of AMFs is essential</h4>

    <p>Our results show that AMF-aware querying only has a positive impact on query evaluation times
if the server can deliver AMF filters sufficiently fast (<em><a href="#question-cache">Research Question 2</a></em>).
Furthermore, if no cache is active, AMF-aware querying performs <em>worse</em> than non-AMF-aware querying.
Ideally, all AMFs should be pre-computed, but due to the large number of possible triple patterns in a dataset,
this is not feasible.
On the other hand, our results have shown that server-side on-the-fly creation of AMFs
only starts to have a significant impact for sizes larger than 10.000 (<em><a href="#question-dynamic-restriction">Research Question 3</a></em>).</p>

    <p>On a low-end machine (2,7 GHz Intel Core i5, 8GB RAM), creation of AMFs takes 0,0125 msec per triple,
which means that AMF creation of size 10.000 takes only 0,125 seconds.
As such, AMFs of size 10.000 or less can be created with acceptable durations for Web servers,
after which they can still be cached.</p>

    <p><a href="#plot_triple_pattern_counts">Fig. 14</a> shows that there is only a very small amount of triple patterns with a very large amount of matches.
When setting the WatDiv dataset to a size of 10M triples, there are only 90 triple patterns with a size larger than 10.000.
Setting that size to 100M triples, this number increases to 255, so this is not a linear increase.
Due to this low number of very large patterns, we can easily pre-compute these offline before dataset publication time.
As the WatDiv dataset achieves a high diversity of <em>structuredness</em>, it is similar to real-world RDF datasets <span class="references">[<a href="#ref-12">12</a>]</span>,
as such this behaviour can be generalized to other datasets with a similar structuredness.</p>

    <figure id="plot_triple_pattern_counts">
<center>
<img src="img/triple_pattern_counts/plot_counts.svg" alt="Triple pattern counts" class="plot_non_c" />
</center>
<figcaption>
        <p><span class="label">Fig. 14:</span> Logarithmic plot of the number of matches for triple patterns in five dataset over varying sizes,
limited to the 1000 patterns with the most matches.
Triple patterns are sorted by decreasing number of matches.</p>
      </figcaption>
</figure>

    <h4 id="bloom-filters-are-preferred-over-gcss-with-active-cache">Bloom filters are preferred over GCSs with active cache</h4>

    <p>Results show that when AMFs are pre-computed,
Bloom filters achieve faster query evaluation times than GCS (<em><a href="#question-cache">Research Question 2</a></em>).
This is because Bloom filter creation requires less effort client-side than GCS due to the simpler decompression,
at the cost of more server effort.
However, this higher server effort is negligible if AMFs can be pre-computed.
As such, we recommend Bloom filters to always be preferred over GCS, unless AMFs can not be cached.</p>

    <h4 id="always-emit-amf-metadata-out-of-band">Always emit AMF metadata out-of-band</h4>

    <p>Our results show that either emitting AMF metadata in-band or out-of-band has no significant impact
on query evaluation times and the total number of HTTP requests (<em><a href="#question-inband">Research Question 5</a></em>).
However, as there may be clients that do no understand AMF metadata,
there will be HTTP data transfer overhead when AMF metadata would be included in-band.
For this reason, we recommend emitting AMF metadata out-of-band without a significant loss in performance for AMF-aware client.</p>

    <h4 id="a-good-trade-off-between-false-positive-probabilities-and-amf-size">A good trade-off between false-positive probabilities and AMF size</h4>

    <p>Lowering the false-positive probability of an AMF increases its size.
As we have seen that larger AMFs have an impact on query evaluation times,
we don’t want AMFs to become too large.
On the other hand, we don’t want the false-positive probabilities to become too low,
as that leads to more unneeded HTTP requests.
Our results have shown that a probability of 1/64 leads to an optimal trade-off for our experiments (<em><a href="#question-probabilities">Research Question 6</a></em>).
However, further research is needed to investigate this trade-off for other types of datasets and queries.</p>

  </section>

  <section id="conclusions">
    <h2>Conclusions</h2>

    <p>In this paper we showed how there are many ways AMF metadata can be used
to increase query performances over TPF endpoints.
Depending on how the metadata is used,
it can have a definite impact on the results.
There are still choices that have to be made sometimes,
depending on factors such as the server capabilities,
expected load, query diversity, data size, and so on.</p>

    <p>To evaluate all these different options,
we made use of the Comunica framework.
In our evaluation section we have clearly shown the added advantage
of using such a framework for testing purposed.
Without much effort, we were capable of running a diverse set of tests over many different configurations.
Whereas this would usually take quite some work to set everything up every time,
and would require multiple implementations,
here we could easily swap out different setups.</p>

    <p>We did not cover everything that is possible with the membership filters for SPARQL queries.
There are still plenty of options that can be researched.
For one there is the heuristic to determine when it is actually profitable to download the filters.
In this paper we presented a simple heuristic 
to determine situations where the extra overhead is actually a disadvantage,
But much more work can be done in fine-tuning this.</p>

    <p>Another avenue that has not yet been tested is how this would perform in a federated environment
and how filters of multiple sources could be combined.
A possibility would be to use the response of one source to filter results on another source,
similar to how <span property="schema:citation http://purl.org/spar/cito/cites" resource="https://dx.doi.org/10.1007/978-3-319-48472-3_48"><a href="https://arxiv.org/pdf/1608.08148.pdf">brTPF</a></span> <span class="references">[<a href="#ref-13">13</a>]</span> sends extra data to a server.</p>

    <p class="todo">If we cut stuff out of the evaluation section we can put it here as future work.</p>

  </section>

</main>

<footer><section id="references">
<h2>References</h2>
<dl class="references">
  <dt id="ref-1">[1]</dt>
  <dd resource="https://dx.doi.org/10.1016/j.websem.2016.03.003" typeof="schema:Article">Verborgh, R., Vander Sande, M., Hartig, O., Van Herwegen, J., De Vocht, L., De Meester, B., Haesendonck, G., Colpaert, P.: Triple Pattern Fragments: a Low-cost Knowledge Graph Interface for the Web. Journal of Web Semantics. 37–38, (2016).</dd>
  <dt id="ref-2">[2]</dt>
  <dd resource="http://rubensworks.net/raw/publications/2017/vtpf.pdf" typeof="schema:Article">Taelman, R., Vander Sande, M., Verborgh, R., Mannens, E.: Versioned Triple Pattern Fragments: A Low-cost Linked Data Interface Feature for Web Archives. In: Proceedings of the 3rd Workshop on Managing the Evolution and Preservation of the Data Web (2017).</dd>
  <dt id="ref-3">[3]</dt>
  <dd resource="http://linkeddatafragments.org/publications/eswc2015.pdf" typeof="schema:Article">Van Herwegen, J., Verborgh, R., Mannens, E., Van de Walle, R.: Query Execution Optimization for Clients of Triple Pattern Fragments. In: The Semantic Web. Latest Advances and New Domains (2015).</dd>
  <dt id="ref-4">[4]</dt>
  <dd resource="#amf2015" typeof="schema:Article">Vander Sande, M., Verborgh, R., Van Herwegen, J., Mannens, E., Van de Walle, R.: Opportunistic Linked Data querying through approximate membership metadata. In: International Semantic Web Conference. pp. 92–110. Springer (2015).</dd>
  <dt id="ref-5">[5]</dt>
  <dd resource="https://comunica.github.io/Article-ISWC2018-Resource/" typeof="schema:Article">Taelman, R., Van Herwegen, J., Vander Sande, M., Verborgh, R.: Comunica: a Modular SPARQL Query Engine for the Web. In: Proceedings of the 17th International Semantic Web Conference (2018).</dd>
  <dt id="ref-6">[6]</dt>
  <dd resource="#watdiv" typeof="schema:Article">Aluç, G., Hartig, O., Özsu, M.T., Daudjee, K.: Diversified stress testing of RDF data management systems. In: International Semantic Web Conference. pp. 197–212. Springer (2014).</dd>
  <dt id="ref-7">[7]</dt>
  <dd resource="#bloomfilter" typeof="schema:Article">Bloom, B.H.: Space/time trade-offs in hash coding with allowable errors. Communications of the ACM. 13, 422–426 (1970).</dd>
  <dt id="ref-8">[8]</dt>
  <dd resource="#gcsfilter" typeof="schema:Article">Putze, F., Sanders, P., Singler, J.: Cache-, hash-, and space-efficient bloom filters. Journal of Experimental Algorithmics (JEA). 14, 4 (2009).</dd>
  <dt id="ref-9">[9]</dt>
  <dd resource="http://componentsjs.readthedocs.io/en/latest/" typeof="schema:CreativeWork">Taelman, R.: Components.js. <a href="http://componentsjs.readthedocs.io/en/latest/">http:/​/​componentsjs.readthedocs.io/en/latest/</a></dd>
  <dt id="ref-10">[10]</dt>
  <dd resource="https://linkedsoftwaredependencies.org/articles/describing-experiments/" typeof="schema:Article">Van Herwegen, J., Taelman, R., Capadisli, S., Verborgh, R.: Describing configurations of software experiments as Linked Data. In: Proceedings of the First Workshop on Enabling Open Semantic Science (SemSci) (2017).</dd>
  <dt id="ref-11">[11]</dt>
  <dd resource="#diefficiency" typeof="schema:Article">Acosta, M., Vidal, M.-E., Sure-Vetter, Y.: Diefficiency metrics: measuring the continuous efficiency of query processing approaches. In: International Semantic Web Conference. pp. 3–19. Springer (2017).</dd>
  <dt id="ref-12">[12]</dt>
  <dd resource="#realism" typeof="schema:Article">Duan, S., Kementsietsidis, A., Srinivas, K., Udrea, O.: Apples and oranges: a comparison of \rdf benchmarks and real \rdf datasets. In: Proceedings of the 2011 ACM SIGMOD International Conference on Management of data. pp. 145–156. ACM, New York, NY, USA (2011).</dd>
  <dt id="ref-13">[13]</dt>
  <dd resource="https://dx.doi.org/10.1007/978-3-319-48472-3_48" typeof="schema:Article">Hartig, O., Buil-Aranda, C.: Bindings-Restricted Triple Pattern Fragments. In: Proceedings of the 15th International Conference on Ontologies, DataBases, and Applications of Semantics. pp. 762–779 (2016).</dd>
</dl>
</section>
</footer>



</body>
</html>
