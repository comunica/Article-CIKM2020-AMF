<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta charset="utf-8" />
  <title>Optimizing Approximate Membership Metadata&lt;br /&gt;in Triple Pattern Fragments for Clients and Servers</title>
  <link rel="stylesheet" media="screen" href="styles/screen.css" />
  <link rel="stylesheet" media="print"  href="styles/print.css" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  
</head>
<body prefix="rdf: http://www.w3.org/1999/02/22-rdf-syntax-ns# rdfs: http://www.w3.org/2000/01/rdf-schema# owl: http://www.w3.org/2002/07/owl# xsd: http://www.w3.org/2001/XMLSchema# dcterms: http://purl.org/dc/terms/ dctypes: http://purl.org/dc/dcmitype/ foaf: http://xmlns.com/foaf/0.1/ v: http://www.w3.org/2006/vcard/ns# pimspace: http://www.w3.org/ns/pim/space# cc: https://creativecommons.org/ns# skos: http://www.w3.org/2004/02/skos/core# prov: http://www.w3.org/ns/prov# qb: http://purl.org/linked-data/cube# schema: http://schema.org/ void: http://rdfs.org/ns/void# rsa: http://www.w3.org/ns/auth/rsa# cert: http://www.w3.org/ns/auth/cert# cal: http://www.w3.org/2002/12/cal/ical# wgs: http://www.w3.org/2003/01/geo/wgs84_pos# org: http://www.w3.org/ns/org# biblio: http://purl.org/net/biblio# bibo: http://purl.org/ontology/bibo/ book: http://purl.org/NET/book/vocab# ov: http://open.vocab.org/terms/ sioc: http://rdfs.org/sioc/ns# doap: http://usefulinc.com/ns/doap# dbr: http://dbpedia.org/resource/ dbp: http://dbpedia.org/property/ sio: http://semanticscience.org/resource/ opmw: http://www.opmw.org/ontology/ deo: http://purl.org/spar/deo/ doco: http://purl.org/spar/doco/ cito: http://purl.org/spar/cito/ fabio: http://purl.org/spar/fabio/ oa: http://www.w3.org/ns/oa# as: https://www.w3.org/ns/activitystreams# ldp: http://www.w3.org/ns/ldp# solid: http://www.w3.org/ns/solid/terms# acl: http://www.w3.org/ns/auth/acl# dio: https://w3id.org/dio# as: https://www.w3.org/ns/activitystreams# oa: http://www.w3.org/ns/oa# ldp: http://www.w3.org/ns/ldp#" typeof="schema:CreativeWork sioc:Post prov:Entity">
  <header>
  <h1 id="optimizing-approximate-membership-metadatabr-in-triple-pattern-fragments-for-clients-and-servers">Optimizing Approximate Membership Metadata<br />in Triple Pattern Fragments for Clients and Servers</h1>

  <ul id="authors">
    <li><a rev="lsc:participatesIn" property="foaf:maker schema:creator schema:author schema:publisher" href="http://www.rubensworks.net/" typeof="foaf:Person schema:Person" resource="https://www.rubensworks.net/#me">Ruben Taelman</a></li>
    <li><a rev="lsc:participatesIn" property="foaf:maker schema:creator schema:author schema:publisher" href="#" typeof="foaf:Person schema:Person" resource="https://data.verborgh.org/people/joachim_van_herwegen">Joachim Van Herwegen</a></li>
    <li><a rev="lsc:participatesIn" property="foaf:maker schema:creator schema:author schema:publisher" href="#" typeof="foaf:Person schema:Person" resource="https://data.verborgh.org/people/miel_vander_sande">Miel Vander Sande</a></li>
    <li><a rev="lsc:participatesIn" property="foaf:maker schema:creator schema:author schema:publisher" href="https://ruben.verborgh.org/" typeof="foaf:Person schema:Person" resource="https://ruben.verborgh.org/profile/#me">Ruben Verborgh</a></li>
  </ul>

  <ul id="affiliations">
    <li id="idlab">IDLab,
          Department of Electronics and Information Systems,
          Ghent University – imec</li>
  </ul>

</header>

<div class="double-column">
    
    <section id="abstract" inlist="" rel="schema:hasPart" resource="#abstract">
<div datatype="rdf:HTML" property="schema:description">
      <h2 property="schema:name">Abstract</h2>
      <!-- Context      -->
      <p>Depending on the HTTP interface used for publishing Linked Data,
the effort of evaluating a SPARQL query
can be redistributed differently between clients and servers.
For instance,
lower server-side CPU usage can be realized at the expense of higher bandwidth consumption.
Previous work has shown that complementing lightweight interfaces
such as Triple Pattern Fragments (TPF) with additional metadata
can positively impact the performance of clients and servers.
<!-- Need         -->
Specifically, Approximate Membership Filters (AMFs)—data structures that are small
and probabilistic—in the context of TPF were shown to reduce the number of HTTP requests,
at the expense of increasing query execution times.
<!-- Task         -->
In order to mitigate this significant drawback,
we have investigated unexplored aspects of AMFs as metadata on TPF interfaces.
<!-- Object       -->
In this article, we introduce and evaluate alternative approaches
for server-side publication and client-side consumption of AMFs within TPF
to achieve faster query execution, while maintaining low server-side effort.
<!-- Findings     -->
Our alternative client-side algorithm
and the proposed server configurations significantly reduce
both the number of HTTP requests and query execution time,
with only a small increase in server load,
thereby mitigating the major bottleneck of AMFs within TPF.
Compared to regular TPF, average query execution is more than 2 times faster
and requires only 10% of the number of HTTP requests,
at the cost of at most a 10% increase in server load.
<!-- Conclusion   -->
These findings translate into
a set of concrete guidelines for data publishers
on how to configure AMF metadata on their servers.
<!-- Perspectives --></p>

    </div>
</section>


<main>
  <!-- Add sections by specifying their file name, excluding the '.md' suffix. -->
  <section id="introduction" inlist="" rel="schema:hasPart" resource="#introduction">
<div datatype="rdf:HTML" property="schema:description">
        <h2 property="schema:name">Introduction</h2>

        <p>SPARQL endpoints,
that expose Linked Data on the Web through a query-based interface,
tend to <a property="schema:citation http://purl.org/spar/cito/cites" href="http://link.springer.com/chapter/10.1007/978-3-642-41338-4_18">suffer from availability issues</a> <span class="references">[<a href="#ref-1">1</a>]</span>.
In comparison to most other HTTP servers,
SPARQL endpoints require high-end computational resources
due the high complexity of SPARQL queries
and can thus be difficult to sustain
when a number of concurrent clients request query execution.
In order to cope with this problem,
the <span property="schema:citation http://purl.org/spar/cito/cites" resource="https://dx.doi.org/10.1016/j.websem.2016.03.003"><a href="http://linkeddatafragments.org/publications/jws2016.pdf">Linked Data Fragments (LDF) effort</a></span> <span class="references">[<a href="#ref-2">2</a>]</span>
has been initiated as a conceptual framework to investigate alternative query interfaces to publish Linked Datasets,
by redistributing the effort of query evaluation between servers and clients.</p>

        <p>LDF interfaces allow some parts of the query to be performed on the server, and some on the client,
which leads to a redistribution of effort between server and client.
This redistribution requires queries to be decomposed into multiple smaller queries,
which typically leads to slower query execution due to the HTTP overhead of these roundtrips,
compared to fully server-side query execution.
In order to reduce this number of smaller queries,
servers could send a pre-filter to the client,
which could potentially eliminate many of these queries.
The focus of this work is investigating such pre-filters.</p>

        <p>In recent years, different kinds of these LDF interfaces have been introduced,
such as <span property="schema:citation http://purl.org/spar/cito/cites" resource="https://dx.doi.org/10.1016/j.websem.2016.03.003"><a href="http://linkeddatafragments.org/publications/jws2016.pdf">Triple Pattern Fragments (TPF)</a></span> <span class="references">[<a href="#ref-2">2</a>]</span>,
<span property="schema:citation http://purl.org/spar/cito/cites" resource="https://dx.doi.org/10.1007/978-3-319-48472-3_48"><a href="https://arxiv.org/pdf/1608.08148.pdf">Bindings-Restricted Triple Pattern Fragments</a></span> <span class="references">[<a href="#ref-3">3</a>]</span>,
SaGe <span class="references">[<a href="#ref-4">4</a>]</span>,
and Smart-KG <span class="references">[<a href="#ref-5">5</a>]</span>.
Each of these types of interfaces introduce their own trade-offs in terms of server and client effort.
Additionally, LDF interfaces can enable feature-based extensibility,
which allows servers to optionally expose certain features as metadata through usage of <span property="schema:citation http://purl.org/spar/cito/cites" resource="https://dx.doi.org/10.1109/MIC.2018.032501515"><a href="https://ruben.verborgh.org/articles/web-api-ecosystem/">self-descriptive hypermedia</a></span> <span class="references">[<a href="#ref-6">6</a>]</span>,
which can then be detected automatically by supporting clients to enhance the query evaluation process.
Due to the extensibility of TPF, <a property="schema:citation http://purl.org/spar/cito/cites" href="http://linkeddatafragments.org/publications/iswc2015-amf.pdf">several interface features have already been proposed for TPF</a> <span class="references">[<a href="#ref-7">7</a>, <a href="#ref-8">8</a>, <a href="#ref-9">9</a>]</span>.
One such feature is <a property="schema:citation http://purl.org/spar/cito/cites" href="http://linkeddatafragments.org/publications/iswc2015-amf.pdf">Approximate Membership Filter (AMF)</a> <span class="references">[<a href="#ref-7">7</a>]</span> metadata,
which supporting clients can use to reduce the number of HTTP requests,
with only a slight increase in server cost.
Unfortunately, this currently comes at the cost of slower query execution,
because the individual HTTP requests were larger and more expensive to compute.
Since TPF is quickly gaining adoption among publishers <span class="references">[<a href="#ref-10">10</a>]</span>,
we focus on improving the performance of AMF with TPF in this work.
AMF could also be useful for other types of LDF interfaces, but we consider this out of scope for this work.</p>

        <p>Even though the work on extending TPF with AMFs showed excessive overhead,
we claim that these problems can be resolved,
and that AMFs can be used to lower overall query execution times without significantly increasing server load.
As such, the goal of our work is to investigate
what changes are required server-side and client-side
to optimize AMFs for TPF.
Concretely, we introduce six dimensions through which the AMF approach from <a property="schema:citation http://purl.org/spar/cito/cites" href="http://linkeddatafragments.org/publications/iswc2015-amf.pdf">Vander Sande et al.</a> <span class="references">[<a href="#ref-7">7</a>]</span> can be improved.
One of these dimensions involves the introduction of a new client-side algorithm to handle AMFs.
The other dimensions are related to the server-side handling of AMFs.
The effects and feasibility of each of these dimensions are evaluated and analyzed in detail.
In summary, our work brings a deeper understanding of the appliance and benefits of AMF metadata for Linked Data interfaces,
so that Linked Data publishers can expose their Linked Datasets in a more efficient manner through TPF interfaces.</p>

      </div>
</section>

  <section id="related-work" inlist="" rel="schema:hasPart" resource="#related-work">
<div datatype="rdf:HTML" property="schema:description">
        <h2 property="schema:name">Related Work</h2>

        <p>In this section we cover the relevant existing research relating to our work.
We start by discussing the TPF interface.
After that, we discuss different AMFs,
followed by their use in query evaluation,
and their use for the TPF interface.</p>

        <h3 id="related-work-ldf">Triple Pattern Fragments</h3>

        <p><span property="schema:citation http://purl.org/spar/cito/cites" resource="https://dx.doi.org/10.1016/j.websem.2016.03.003"><a href="http://linkeddatafragments.org/publications/jws2016.pdf">Linked Data Fragments (LDF)</a></span> <span class="references">[<a href="#ref-2">2</a>]</span>
is a conceptual framework to study
interfaces for publishing Linked Data,
by comparing server and client effort.
During query execution, some LDFs may require a low server effort,
at the cost of increased client-side querying effort (<em>e.g. data dumps</em>).
while others require a high server effort,
at the cost of minimal client-side effort (<em>e.g. SPARQL endpoint</em>).
The <span property="schema:citation http://purl.org/spar/cito/cites" resource="https://dx.doi.org/10.1016/j.websem.2016.03.003"><a href="http://linkeddatafragments.org/publications/jws2016.pdf">Triple Pattern Fragments (TPF) interface</a></span> <span class="references">[<a href="#ref-2">2</a>]</span> was introduced
as a trade-off between those extremes,
by restricting the server interface to triple pattern queries,
and leaving the remainder of query evaluation to the client.
Compared to SPARQL endpoints,
TPF in general reduces the required server-side capacity and load
for query evaluation
at the expense of more bandwidth usage and slower query times.
Results show that the number of HTTP requests forms the primary bottleneck during querying.</p>

        <p>TPF follows the REST architectural style,
and aims to be a fully self-descriptive API.
TPF achieves this by including <em>metadata</em> and declarative <em>controls</em> in all of its RDF responses next to the main data.
The metadata can contain anything that may be useful for clients during query execution,
such as cardinality estimates.</p>

        <h3 id="approximate-membership-functions">Approximate Membership Functions</h3>

        <p>Approximate Membership Functions (AMFs) are probabilistic data structures
that efficiently can determine membership of a set,
at the cost of false positives.
They are typically much smaller than a full dataset,
making them a useful pre-filtering method.
When selecting among different AMF techniques,
we need to take into account
trade-offs between filter size and false-positive rate.</p>

        <p><a property="schema:citation http://purl.org/spar/cito/cites" href="http://crystal.uta.edu/~mcguigan/cse6350/papers/Bloom.pdf"><em>Bloom filters</em></a> <span class="references">[<a href="#ref-11">11</a>]</span> and <a property="schema:citation http://purl.org/spar/cito/cites" href="https://www.cs.amherst.edu/~ccmcgeoch/cs34/papers/cacheefficientbloomfilters-jea.pdf"><em>Golomb-coded sets</em> (GCS)</a> <span class="references">[<a href="#ref-12">12</a>]</span>
are examples of AMF techniques.
Both approaches guarantee a 100% recall, but not a 100% precision.
A Bloom filter is essentially a bitmap filled with the range of a predefined number of hash functions.
Elements are added to the filter by applying all hash functions,
and <code>OR</code>-ing the results into the bitmap.
Afterwards, membership tests can be done by applying all hash functions again,
and performing a bit-wise <code>AND</code> to see if all results are <em>possibly</em> present.
GCS were introduced as an improvement to Bloom filters
by using only a single hash function.
Furthermore, the range of the hash function is always a uniformly distributed list instead of a bitmap,
which allows for more <a property="schema:citation http://purl.org/spar/cito/cites" href="https://ieeexplore.ieee.org/abstract/document/1055357/">efficiency compression using geometric distributions</a> <span class="references">[<a href="#ref-13">13</a>]</span>.
Compared to Bloom filters, GCS achieve a higher compression rate, at the cost of slower decompression.</p>

        <h3 id="approximate-membership-for-query-evaluation">Approximate Membership for Query Evaluation</h3>

        <p>AMFs find their use in many areas related to RDF querying,
such as join optimization and source selection.</p>

        <p>AMFs have been proven to be a useful tool for improving the performance of <em>graph pattern joins</em>.
Bloom filters can therefore be used to
<a property="schema:citation http://purl.org/spar/cito/cites" href="https://dl.acm.org/citation.cfm?id=2063784">efficiently group connected triple patterns by frequency</a> <span class="references">[<a href="#ref-14">14</a>]</span>,
to improve the efficiency of merge joins <a property="schema:citation http://purl.org/spar/cito/cites" href="https://www.researchgate.net/profile/Thomas_Neumann2/publication/47863714_Scalable_Join_Processing_on_Very_Large_RDF_Graphs/links/00b7d51d1687cae740000000.pdf">as a way of representing equivalent classes</a> <span class="references">[<a href="#ref-15">15</a>]</span>,
and for <a property="schema:citation http://purl.org/spar/cito/cites" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8406674">joining distributed and stored streams</a> <span class="references">[<a href="#ref-16">16</a>]</span>.</p>

        <p>Furthermore, Bloom filters are also used in the domain of federated querying to
optimize the process of <em>source selection</em>.
Concretely, <a property="schema:citation http://purl.org/spar/cito/cites" href="https://domino.mpi-inf.mpg.de/intranet/ag5/ag5publ.nsf/0/DAAD136B50B0C0ECC12579E6004D6582/$file/p2-hose.pdf">SPARQL’s boolean ASK response can be enhanced with Bloom filters as a way of sharing a concise summary of the matching results</a> <span class="references">[<a href="#ref-17">17</a>]</span>.
This allows source selection algorithms to identify overlap between different sources,
and can either minimize the required number of requests,
or it can be used to retrieve as many results as possible.</p>

        <h3 id="related-work-amf">Approximate Membership Metadata for TPF</h3>

        <p>Pure TPF query plans typically <a property="schema:citation http://purl.org/spar/cito/cites" href="http://linkeddatafragments.org/publications/iswc2015-amf.pdf">produce a large number of <em>membership requests</em></a> <span class="references">[<a href="#ref-7">7</a>]</span>,
checking whether a specific triple (without variables) is present in a dataset.
Due to the significant number of HTTP requests that these membership requests require,
these can cause unacceptably high query execution times.
The authors have shown 50% of all requests are membership requests for 1 in 3 queries,
which indicates that optimizing membership queries can have a positive effect on query evaluation.</p>

        <p>In the spirit of LDF,
servers can combine multiple interface features
to assist supporting clients with query evaluation.
An interface feature with <em>approximate membership metadata</em>
for all variables in the requested <em>triple patterns</em>
<a property="schema:citation http://purl.org/spar/cito/cites" href="http://linkeddatafragments.org/publications/iswc2015-amf.pdf">considerably reduced the number of membership requests to a server</a> <span class="references">[<a href="#ref-7">7</a>]</span>.
In order to reduce unneeded data transfer to clients that are unable to handle AMF metadata,
the actual binary AMFs are included out-of-band behind a link in the metadata.
Client-side query engines can detect this AMF metadata,
and use it to test the membership of triples.
Clients can skip many membership requests by ruling out true negatives
(because of the 100% recall of AMFs),
leaving only HTTP requests to distinguish false from true positives
(because of the &lt;100% precision).
More details on the exact representation of this AMF metadata can be found on <a href="https://github.com/comunica/Article-SSWS2020-AMF/wiki/AMF-metadata">https:/​/​github.com/comunica/Article-SSWS2020-AMF/wiki/AMF-metadata</a>.</p>

        <p>The results of this work show that there is a significant decrease in HTTP requests when AMFs are used,
at the cost of only a small increase in server load.
However,
even though the <em>number</em> of HTTP requests was lower (reduction of 33%),
the <em>total execution time increased</em> for most queries,
because of the long server delays when generating AMFs.
In this work, we aim to solve this problem of higher execution times.</p>

      </div>
</section>

  <section id="problem-statement" inlist="" rel="schema:hasPart" resource="#problem-statement">
<div datatype="rdf:HTML" property="schema:description">
        <h2 property="schema:name">Problem Statement</h2>

        <p>The goal of our work is to optimize query execution over TPF interfaces using AMFs.
We build upon the work from <a property="schema:citation http://purl.org/spar/cito/cites" href="http://linkeddatafragments.org/publications/iswc2015-amf.pdf">Vander Sande et al.</a> <span class="references">[<a href="#ref-7">7</a>]</span>,
where the authors allowed the number of HTTP requests to be reduced
at the cost of slower query execution.
Our goal is to mitigate this major drawback, while retaining its advantages.</p>

        <p>Vander Sande et al. introduced a number of follow-up questions
that we use as a basis for defining our research questions.
Concretely, in order to mitigate the earlier mentioned drawbacks,
our research questions are defined as follows:</p>

        <ol>
          <li id="question-combine"><strong>Can query execution time be lowered by combining triple pattern AMFs client-side on larger Basic Graph Patterns (BGPs)?</strong>
<br />
Earlier work focused on using AMF metadata from triple pattern queries
to test the membership of materialized triples,
while there is potential for exploiting this for other types of patterns in the query as well.
For instance, combining multiple AMFs at BGP-level
by applying AMFs on triple patterns with shared variables.</li>
          <li id="question-cache"><strong>To what extent do HTTP caching and AMFs speed up query execution?</strong>
<br />
As Vander Sande et al. suggest that caching of AMFs
reduce server delays, we investigate the impact of caching HTTP requests and/or AMFs.</li>
          <li id="question-dynamic-restriction"><strong>How does selectively enabling AMF impact server load and querying?</strong>
<br />
Earlier work introduced AMF as a feature that was always enabled.
However, some specific AMFs may be too expensive for servers to calculate on the fly.
As such, it may be beneficial to only enable AMF for queries
that have a result count lower than a certain threshold.</li>
          <li id="question-bandwidth"><strong>How does network bandwidth impact query performance with AMFs?</strong>
<br />
In experiments by Vander Sande et al., the HTTP bandwidth was set to a realistic 1Mbps.
However, there is still an open question as to what extent different rates have an impact on the importance of AMF.</li>
          <li id="question-probabilities"><strong>How low can AMF false-positive probabilities become to still achieve decent client-side query performance?</strong>
<br />
Based on their results, Vander Sande et al. have suggested that additional experimentation is needed with regards
to lower <em>AMF false-positive probabilities</em>, as higher probabilities did not have a significant effect on query performance.
Note that query correctness is never affected,
but rather the number of requests to the server,
since every positive match requires a request
to verify whether it is a true or false positive.</li>
        </ol>

        <p>An answer to these research questions will be formed using the experiments from <a href="#evaluation">Section 5</a>.</p>

      </div>
</section>

  <section id="solution" inlist="" rel="schema:hasPart" resource="#solution">
<div datatype="rdf:HTML" property="schema:description">
        <h2 property="schema:name">Client-side AMF Algorithms</h2>

        <p>In this section, we explain the existing triple-based AMF algorithm, and we show where it lacks.
Following that, we introduce a new client-side BGP-based AMF algorithm that solves these problems.
For the reader’s convenience, detailed examples of how these two algorithms work can be found on <a href="https://github.com/comunica/Article-SSWS2020-AMF/wiki/AMF-algorithm-examples">https:/​/​github.com/comunica/Article-SSWS2020-AMF/wiki/AMF-algorithm-examples</a>.
Finally, we introduce a heuristic that determines whether or not the BGP-based algorithm is beneficial to use.</p>

        <h3 id="triple-based-amf-algorithm">Triple-based AMF Algorithm</h3>

        <figure id="amf-triple-pseudo" class="listing">
<pre><code>function hasTriple(triple, context) {
</code><code>  for position in [&#39;subject&#39;, &#39;predicate&#39;, &#39;object&#39;]
</code><code>    if !context.amf[position].contains(triple[position])
</code><code>      return false;
</code><code>  return super.hasTriple(triple, context);
</code><code>}</code></pre>
<figcaption>
            <p><span class="label">Listing 1:</span> Triple-based AMF algorithm by <a property="schema:citation http://purl.org/spar/cito/cites" href="http://linkeddatafragments.org/publications/iswc2015-amf.pdf">Vander Sande et al.</a> <span class="references">[<a href="#ref-7">7</a>]</span>
as a pre-filtering step for testing the membership of triples.</p>
          </figcaption>
</figure>

        <p><a property="schema:citation http://purl.org/spar/cito/cites" href="http://linkeddatafragments.org/publications/iswc2015-amf.pdf">Vander Sande et al.</a> <span class="references">[<a href="#ref-7">7</a>]</span> introduced an algorithm
that acts as a cheap pre-processing step for <em>testing the membership of triples</em>.
This algorithm was used in combination with the streaming <span property="schema:citation http://purl.org/spar/cito/cites" resource="https://dx.doi.org/10.1016/j.websem.2016.03.003"><a href="http://linkeddatafragments.org/publications/jws2016.pdf">greedy client-side TPF algorithm</a></span> <span class="references">[<a href="#ref-2">2</a>]</span> for evaluating SPARQL queries.
<a href="#amf-triple-pseudo">Listing 1</a> depicts this algorithm in pseudo-code.</p>

        <p>Concretely, every triple pattern that has all of its variables resolved to constants
is run through this function right before more a expensive HTTP request would be performed.
This function takes a triple and a query context containing the AMFs
that were detected during the last TPF response for that pattern.
It will test the AMFs for all triple components, and from the moment that a true negative is found, false will be returned.
Once all checks pass, the original HTTP-based membership logic will be invoked.</p>

        <h3 id="bgp-based-amf-algorithm">BGP-based AMF Algorithm</h3>

        <p>Following the idea of the <em>triple-based</em> algorithm,
we introduce an extension that applies this concept for <em>BGPs</em>.
This makes it possible to use AMFs not only for testing the membership of triples,
but also for using AMFs to test partially bound triple patterns that may still have variables.
In theory, this should filter (true negative) bindings earlier in the query evaluation process.</p>

        <figure id="amf-bgp-pseudo" class="listing">
<pre><code>function getBindings(triplePatterns, context) {
</code><code>  for ((triplePattern, amf) in (triplePatterns, context.amfs))
</code><code>    for position in [&#39;subject&#39;, &#39;predicate&#39;, &#39;object&#39;]
</code><code>      if ((!triplePattern[position].isVariable()
</code><code>          &amp;&amp; !amf[position].contains(triplePattern.subject))
</code><code>        return new EmptyStream();
</code><code>  return super.getBindings(triplePatterns, context);
</code><code>}</code></pre>
<figcaption>
            <p><span class="label">Listing 2:</span> BGP-based AMF algorithm as a pre-filtering step for BGP evaluation.</p>
          </figcaption>
</figure>

        <p><a href="#amf-bgp-pseudo">Listing 2</a> shows this algorithm in pseudo-code.
Just like the triple-based algorithm, it acts as a pre-processing step when BGPs are being processed.
It takes a list of triple patterns as input, and query context containing a list of corresponding AMFs
that were detected during the last TPF responses for each respective pattern.
The algorithm iterates over each pattern,
and for each triple component that is not a variable, it will run it through its AMF.
Once a true negative is found, it will immediately return an empty stream to indicate that this BGP definitely contains no results.
If all checks on the other hand pass, the original BGP logic will be invoked,
which will down the line invoke more expensive HTTP requests.</p>

        <h3 id="heuristic-for-enabling-the-bgp-algorithm">Heuristic for Enabling the BGP Algorithm</h3>

        <p>While our BGP-based algorithm may filter out true negative bindings sooner than the the triple-based algorithm,
it may lead to larger AMFs being downloaded, possibly incurring a larger HTTP overhead.
In some cases, this cost may become too high if the number of bindings that needs to be tested is low,
e.g. downloading an AMF of 10MB would be too costly when only a single binding needs to be tested.
To cope with these cases, we introduce a heuristic in <a href="#amf-bgp-heuristic-pseudo">Listing 3</a>,
that will estimate whether or not the BGP-based algorithm will be cheaper in terms of HTTP overhead
compared to just executing the HTTP membership requests directly.
Concretely, the heuristic checks if the size of an AMF is lower than the size of downloading TPF responses.
This heuristic has been designed for fast calculation,
with exactness as a lower priority.
Based on measurements, we set <code>AMF_TRIPLE_SIZE</code> to 2 bytes,
and <code>TPF_BINDING_SIZE</code> to 1000 bytes by default.
In <a href="#evaluation">Section 5</a>, we will evaluate the effects for different <code>TPF_BINDING_SIZE</code> values.
In future work, more exact heuristics should be investigated
that take perform live profiling of HTTP requests and delays to avoid the need of these constants.</p>
        <figure id="amf-bgp-heuristic-pseudo" class="listing">
<pre><code>function preferAmfForBgp(bindingsCount, triplePatternsCardinality) {
</code><code>  totalAmfsSize = triplePatternsCardinality.sum() * AMF_TRIPLE_SIZE;
</code><code>  joinRequestData = (bindingsCount * triplePatternsCardinality.length)
</code><code>      * TPF_BINDING_SIZE;
</code><code>  return totalAmfsSize &lt; joinRequestData;
</code><code>}
</code></pre>
<figcaption>
            <p><span class="label">Listing 3:</span> Heuristic for checking if the BGP-based AMF algorithm should be executed,
where <code>bindingsCount</code> is the number of intermediary bindings for the current BGP,
and <code>triplePatternsCardinality</code> is an array of cardinality estimates for each triple pattern in the BGP.
<code>AMF_TRIPLE_SIZE</code> is a parameter indicating the number of bytes required to represent a triple inside an AMF,
and <code>TPF_BINDING_SIZE</code> is the size in bytes of a single TPF response.</p>
          </figcaption>
</figure>

      </div>
</section>

  <section id="evaluation" inlist="" rel="schema:hasPart" resource="#evaluation">
<div datatype="rdf:HTML" property="schema:description">
        <h2 property="schema:name">Evaluation</h2>

        <p>The goal of this section is to answer the research questions from <a href="#problem-statement">Section 3</a>.
First, we briefly discuss the implementations of our algorithm.
After that, we present our experimental setup, and we present our results.
All code and results results can be found on <a href="https://github.com/comunica/comunica-feature-amf" class="mandatory" data-link-text="https:/​/​github.com/​comunica/​comunica-​feature-​amf">GitHub</a>.</p>

        <h3 id="implementation">Implementation</h3>

        <p>For implementing the client-side AMF algorithms,
we make use of JavaScript-based <a property="schema:citation http://purl.org/spar/cito/cites" href="https://comunica.github.io/Article-ISWC2018-Resource/">Comunica SPARQL querying framework</a> <span class="references">[<a href="#ref-18">18</a>]</span>.
Since Comunica already fully supports the TPF algorithm,
we could implement our algorithms as fully standalone plugins.
Our algorithms are implemented in separate Comunica modules,
and will be available open-source on GitHub.
Concretely, we implemented the original triple-based AMF algorithm,
our new BGP-based AMF algorithm (<em>BGP Simple</em>),
and a variant of this BGP-based algorithm (<em>BGP Combined</em>) that pre-fetches AMFs in parallel.</p>

        <p>The original TPF server extension in <a href="https://github.com/LinkedDataFragments/Server.js/tree/feature-handlers-amf">the LDF server software</a>
by <a property="schema:citation http://purl.org/spar/cito/cites" href="http://linkeddatafragments.org/publications/iswc2015-amf.pdf">Vander Sande et al.</a> <span class="references">[<a href="#ref-7">7</a>]</span>
allowed both Bloom filters and GCS to be created on the fly for any triple pattern.
To support our experiments, we extended this implementation with new features.
This implementation is available on <a href="https://github.com/LinkedDataFragments/Server.js/tree/feature-handlers-amf-2" class="mandatory" data-link-text="https:/​/​github.com/​LinkedDataFragments/​Server.js/​tree/​feature-​handlers-​amf-​2">GitHub</a>.
In order to measure the server overhead of large AMFs,
we added a config option to dynamically enable AMFs for triple patterns
with number of matching triples below a given result count threshold.
Next to that, we implemented an optional file-based cache to avoid recomputing AMFs
to make pre-computation of AMFs possible.</p>

        <h3 id="experimental-setup">Experimental Setup</h3>

        <p>Based on our LDF server and Comunica implementations that were discussed in <a href="#implementation">Subsection 5.1</a>,
we defined five experiments, corresponding to our five research questions from <a href="#problem-statement">Section 3</a>.
These experiments are defined and executed using <a href="https://github.com/comunica/comunica-bencher" class="mandatory" data-link-text="https:/​/​github.com/​comunica/​comunica-​bencher">Comunica Bencher</a>,
which is a Docker-based benchmark execution framework for evaluating Linked Data Fragments.
This enables reproducibility of these experiments, as they can be re-executed with a single command.</p>

        <p>The following experiments execute WatDiv with a dataset scale of 100
and a query count of 5 for the default query templates, leading to a total of 100 queries.
We only report results for Bloom filters for experiments
where no significant difference was measured with GCS.
Each experiment includes a warmup phase,
and averages results over 3 separate runs.
During this warmup phase, the server caches all generated AMFs.
For each query, 
the client-side timeout was set to 5 minutes and, to enforce a realistic Web bandwidth,
the network delay was set to 1024Kbps.
All experiments were executed on a 64-bit Ubuntu 14.04 machine with 128 GB of memory and a 24-core 2.40 GHz CPU—each Docker container was limited to one CPU core, behind an NGINX HTTP cache.</p>

        <ol>
          <li><strong>Client-side AMF Algorithms</strong>:
 In this experiment, we compare different client-side algorithms
 (<em>None, Triple, BGP Simple, BGP Combined, Triple with BGP Combined</em>)
 for using AMF metadata.</li>
          <li><strong>Caching</strong>:
 In this experiment, we evaluate the effects of caching all HTTP requests combined with caching AMF filters server-side,
 both following the LRU cache replacement strategy.
 We also compare the effects of using AMF metadata client-side or not.
 Finally, we test the effects of warm and cold caches.</li>
          <li><strong>Dynamically Enabling AMF</strong>:
 In this experiment, we compare different result count thresholds (<em>0, 1.000, 10.000, 100.000, 1.000.000</em>) with each other,
 with either the server-side AMF filter cache enabled or not.
 We disable the HTTP cache and warmup phase to evaluate a cold-start.</li>
          <li><strong>Network Bandwidths</strong>:
 Different network bandwidths (<em>256kbps, 512kbps, 2048kbps, 4096kbps</em>) are tested for evaluating network speedups,
 and their effects or different AMF algorithms (<em>None, Triple, BGP Combined</em>) are tested.</li>
          <li><strong>False-positive Probabilities</strong>:
 In this final experiment, we compare different AMF false-positive probabilities (<em>1/4096, 1/1024, 1/64, 1/4, 1/2</em>).</li>
        </ol>

        <h3 id="results">Results</h3>

        <p>In this section, we present the results for each of our experiments separately.
We analyzed our results statistically by comparing means using the Kruskal-Wallis test,
and report on their p-values (<em>low values indicate non-equal means</em>).</p>

        <h4 class="display-block" id="client-side-amf-algorithms">Client-side AMF Algorithms</h4>

        <figure id="plot_client_algos">
<center>
<img src="img/experiments/client_algos/plot_no_c.svg" alt="Client-side AMF Algorithms (non-C)" class="plot_non_c" />
<img src="img/experiments/client_algos/plot_c.svg" alt="Client-side AMF Algorithms (C)" class="plot_c" />
</center>
<figcaption>
            <p><span class="label">Fig. 1:</span> Query evaluation times for the different client-side algorithms for using AMF metadata, lower is better.
BGP-based approaches are mostly faster.</p>
          </figcaption>
</figure>

        <figure id="plot_query_times_F3">
<center>
<img src="img/experiments/client_algos/query_times_F3.svg" alt="Query Times for F3 over different Client-side AMF Algorithms" class="plot_non_c" />
</center>
<figcaption>
            <p><span class="label">Fig. 2:</span> Query result arrival times for query F3 for the different client-side algorithms.
BGP-based algorithms introduce a delay until first result, but produce results at a higher rate after this delay.</p>
          </figcaption>
</figure>

        <figure id="http_requests_cache">

          <table>
            <thead>
              <tr>
                <th>Approach</th>
                <th style="text-align: right">Requests</th>
                <th style="text-align: right">Relative requests</th>
                <th style="text-align: right">Cache hits</th>
                <th style="text-align: right">Cache hit rate</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>None</td>
                <td style="text-align: right">1,911,845</td>
                <td style="text-align: right">100.00%</td>
                <td style="text-align: right">1,686,889</td>
                <td style="text-align: right">88.23%</td>
              </tr>
              <tr>
                <td>Triple</td>
                <td style="text-align: right">1,837,886</td>
                <td style="text-align: right">96.13%</td>
                <td style="text-align: right">1,626,611</td>
                <td style="text-align: right">88.50%</td>
              </tr>
              <tr>
                <td>BGPSimple</td>
                <td style="text-align: right">191,764</td>
                <td style="text-align: right">10.03%</td>
                <td style="text-align: right">173,617</td>
                <td style="text-align: right">90.53%</td>
              </tr>
              <tr>
                <td>BGPCombined</td>
                <td style="text-align: right">191,768</td>
                <td style="text-align: right">10.03%</td>
                <td style="text-align: right">173,621</td>
                <td style="text-align: right">90.53%</td>
              </tr>
              <tr>
                <td>TripleBGP</td>
                <td style="text-align: right">191,773</td>
                <td style="text-align: right">10.03%</td>
                <td style="text-align: right">173,626</td>
                <td style="text-align: right">90.53%</td>
              </tr>
            </tbody>
          </table>

          <figcaption>
            <p><span class="label">Fig. 3:</span> Number of HTTP requests, number of HTTP requests relative to not using AMFs, number of cache hits and cache hit rate for the different client-side algorithms.
BGP-based algorithms require significantly fewer HTTP requests.</p>
          </figcaption>
        </figure>

        <figure id="plot_skip_bgp_heuristic">
<center>
<img src="img/experiments/skip_bgp_heuristic/plot_no_c.svg" alt="Client-side AMF Algorithms with BGP skipping heuristic (non-C)" class="plot_non_c" />
<img src="img/experiments/skip_bgp_heuristic/plot_c.svg" alt="Client-side AMF Algorithms with BGP skipping heuristic (C)" class="plot_c" />
</center>
<figcaption>
            <p><span class="label">Fig. 4:</span> Query evaluation times when enabling the heuristic in the client-side combined BGP algorithm.
The heuristic shows a slight improvement in most cases.</p>
          </figcaption>
</figure>

        <p><a href="#plot_client_algos">Fig. 1</a> shows the query evaluation times for our first experiment
on the different client-side algorithms for using AMF metadata.
In line with what was shown in the <a property="schema:citation http://purl.org/spar/cito/cites" href="http://linkeddatafragments.org/publications/iswc2015-amf.pdf">first TPF AMF experiments</a> <span class="references">[<a href="#ref-7">7</a>]</span>,
the triple-based algorithm reduces query evaluation times in only 2 of the 20 queries.
Our new BGP-based algorithms on the other hand reduce query evaluation times and outperforms the triple-based algorithm.
Only for 5 of the 20 queries, evaluation times are higher or equal.
Our combined BGP algorithm is slightly faster than the simple BGP algorithm.
By using both the combined BGP-based and the triple-based algorithms, we can reduce evaluation times slightly further.</p>

        <p><a href="#plot_query_times_F3">Fig. 2</a> shows the query result arrival times for query F3,
and is similar to the arrival times for other queries.
This figure shows that the time-until-first-result is the highest for BGP-based AMF algorithms.
However, once this first results comes in, the arrival rate becomes much higher compared to the other algorithms.
This delay for the BGP-based algorithms is caused by the higher download times for large AMFs,
and explains the higher or equal evaluation times for 5 of the 20 queries.</p>

        <p><a href="#http_requests_cache">Fig. 3</a> shows the BGP-based algorithms significantly lower the number of required HTTP requests,
which explains the significant reduction in query execution times.
This allows the NGINX cache hit rate to slightly increase compared to the regular and triple-based TPF algorithms,
since fewer requests are made, which lowers the number of required cache evictions.</p>

        <p>Based on these results, there is <em>no statistically significant difference</em>
between the evaluation times of the triple-based AMF algorithm, and not using AMF metadata at all (<em>p-value: 0.9318</em>).
The simple and combined BGP algorithms are significantly faster than not using AMF metadata (<em>p-values: 0.0062, 0.0026</em>).
Furthermore, the simple and combined BGP algorithm are on average
more than twice as fast as the triple-based algorithm,
which make them significantly faster (<em>p-values: 0.0090, 0.0041</em>).
Furthermore, combining our simple and combined BGP algorithm with the triple-based algorithms
shows no further statistically significant improvement (<em>p-values: 0.9484, 0.6689</em>).</p>

        <p>In <a href="#plot_skip_bgp_heuristic">Fig. 4</a>, we show the results where we apply the heuristic
for dynamically disabling the BGP heuristic based on different parameter values.
On average, setting the request size parameter value to 2000 has the lowest average evaluation time for this experiment.
This case achieves lower evaluation times for 19 of the 20 queries,
which is an improvement compared to not using the heuristic.
This improvement by itself however only small, and not statistically significant (<em>p-value: 0.1842</em>).</p>

        <h4 class="display-block" id="caching">Caching</h4>

        <figure id="plot_caching">
<center>
<img src="img/experiments/caching/plot_no_c.svg" alt="Caching (non-C)" class="plot_non_c" />
<img src="img/experiments/caching/plot_c.svg" alt="Caching (C)" class="plot_c" />
</center>
<figcaption>
            <p><span class="label">Fig. 5:</span> Logarithmic query evaluation times comparing server-side HTTP and AMF caching.
Not caching anything is always slower than caching HTTP responses or AMFs.</p>
          </figcaption>
</figure>

        <p><a href="#plot_caching">Fig. 5</a> shows that caching either HTTP requests or AMF filters server-side has a significant positive effect on query evaluation times (<em>p-value: &lt; 0.0001</em>).
We observe that caching HTTP requests reduces query evaluation times <em>more</em> than just caching AMF filters (<em>p-value: 0.0225</em>).
Furthermore, there is no significant difference between query evaluation times for caching of both HTTP requests and AMF filters
compared to just caching HTTP requests (<em>p-value: 0.7694</em>).
This shows that an HTTP cache achieves the best results,
and additionally caching AMF filters server-side is not worth the effort.</p>

        <p>If we compare these results with the results for non-AMF-aware querying,
we see that if HTTP caching is <em>disabled</em>, query evaluation times for non-AMF-aware querying are <em>significantly lower</em> than AMF-aware approaches (<em>p-value: &lt; 0.0001</em>).
On the other hand, if HTTP caching is <em>enabled</em>, query evaluation times for non-AMF-aware querying are <em>significantly worse</em> than with AMF-aware approaches (<em>p-value: &lt; 0.0001</em>).
While caching is already very important for TPF-based querying,
these results show that caching becomes <em>even more important</em> when AMFs are being used.</p>

        <p>Finally, our results show that when our cache is warm, exposing Bloom filters instead of GCS achieves faster query evaluation times.
While there are a few outliers where GCS is two to three times slower,
the difference is only small in most cases (<em>p-value: 0.1786</em>).</p>

        <h4 class="display-block" id="dynamically-enabling-amf">Dynamically Enabling AMF</h4>

        <figure id="plot_server_metadata_enabled_cached">
<center>
<img src="img/experiments/server_metadata_enabled/plot_cached_no_c.svg" alt="Effect of AMF result count thresholds with HTTP cache (non-C)" class="plot_non_c" />
<img src="img/experiments/server_metadata_enabled/plot_cached_c.svg" alt="Effect of AMF result count thresholds with HTTP cache (C)" class="plot_c" />
</center>
<figcaption>
            <p><span class="label">Fig. 6:</span> Query evaluation times for different AMF result count thresholds and AMF algorithms when HTTP caching is enabled.
Low result count thresholds slow down query execution.</p>
          </figcaption>
</figure>

        <figure id="plot_server_metadata_enabled_notcached">
<center>
<img src="img/experiments/server_metadata_enabled/plot_notcached_no_c.svg" alt="Effect of AMF result count thresholds without HTTP cache (non-C)" class="plot_non_c" />
<img src="img/experiments/server_metadata_enabled/plot_notcached_c.svg" alt="Effect of AMF result count thresholds without HTTP cache (C)" class="plot_c" />
</center>
<figcaption>
            <p><span class="label">Fig. 7:</span> Query evaluation times for different AMF result count thresholds and AMF algorithms when HTTP caching is disabled.
High result count thresholds slow down query execution.</p>
          </figcaption>
</figure>

        <figure id="plot_threshold_serverload">
<center>
<img src="img/experiments/server_metadata_enabled/threshold_serverload.svg" alt="Server CPU usage for AMF result counts" class="plot_non_c" style="width: 18em !important;" />
</center>
<figcaption>
            <p><span class="label">Fig. 8:</span> Average server CPU usage increases when AMF result count thresholds increase
when caching is disabled, but much slower if caching is enabled.</p>
          </figcaption>
</figure>

        <p><a href="#plot_server_metadata_enabled_cached">Fig. 6</a> shows lower server-side AMF result count thresholds
lead to higher query evaluation times when HTTP caching is enabled (<em>p-value: &lt; 0.0001</em>).
<a href="#plot_server_metadata_enabled_notcached">Fig. 7</a> shows that AMF result count thresholds
also have an impact on query evaluation times when HTTP caching is disabled (<em>p-value: 0.0005</em>),
but it does not necessarily lower it.
For this experiment, setting the threshold to 10K leads to the lowest overall query evaluation times.</p>

        <p><a href="#plot_threshold_serverload">Fig. 8</a> shows that lower AMF result count thresholds lead to lower server loads
when HTTP caching is disabled (<em>p-value: 0.0326</em>).
On the other hand, if HTTP caching is enabled,
there is no correlation (<em>Pearson</em>) between AMF result count threshold and server CPU usage (<em>p-value: 0.4577</em>).
This shows that if caching is enabled, dynamically enabling AMFs based on the number of triples
is not significantly important,
and may therefore be disabled to always expose AMFs.</p>

        <p>For this experiment, average CPU usage increased from 31.65% (no AMF) to 40.56% (all AMF) when caching is enabled.
Furthermore, when looking at the raw HTTP logs,
we observe that by <em>always</em> exposing AMFs, we use 28.66% of the total number of HTTP requests compared to not exposing AMFs.
As such, AMFs significantly reduce the number of HTTP requests at the cost of ~10% more server load.</p>

        <h4 class="display-block" id="network-bandwidth">Network Bandwidth</h4>

        <figure id="plot_delay_none">
<center>
<img src="img/experiments/delay/plot_none_no_c.svg" alt="Effect of bandwidth on non-AMF (non-C)" class="plot_non_c" />
<img src="img/experiments/delay/plot_none_c.svg" alt="Effect of bandwidth on non-AMF (C)" class="plot_c" />
</center>
<figcaption>
            <p><span class="label">Fig. 9:</span> When AMF is not used, query evaluation times decrease with increased bandwidth up until 2048kbps.</p>
          </figcaption>
</figure>

        <figure id="plot_delay_triple">
<center>
<img src="img/experiments/delay/plot_triple_no_c.svg" alt="Effect of bandwidth on triple AMF (non-C)" class="plot_non_c" />
<img src="img/experiments/delay/plot_triple_c.svg" alt="Effect of bandwidth on triple AMF (C)" class="plot_c" />
</center>
<figcaption>
            <p><span class="label">Fig. 10:</span> When the triple-based AMF algorithm is used, query evaluation times also decrease with increased bandwidth up until 2048kbps.</p>
          </figcaption>
</figure>

        <p><a href="#plot_delay_none">Fig. 9</a>, <a href="#plot_delay_triple">Fig. 10</a> and <a href="#plot_delay_bgp">Fig. 11</a> show the effects of different bandwidths
on query evaluation times over different algorithms.
We observe that when not using AMF, or using the triple-level AMF algorithm,
lower bandwidths lead to higher query evaluation times.
However, when bandwidths become much higher,
query evaluation times decrease at a lower rate.
In contrast, the BGP-level AMF algorithm continuously becomes faster when bandwidth increases.
We do not measure any significant impact of bandwidth on both non-AMF usage and triple-level AMF usage (<em>p-values: 0.2905, 0.2306</em>).
For BGP-level AMF, we measure a significant impact (<em>p-value: 0.0028</em>).
This shows that <em>if</em> BGP-level AMF is used,
then higher bandwidths can be exploited <em>more</em> for faster query evaluation.</p>

        <figure id="plot_delay_bgp">
<center>
<img src="img/experiments/delay/plot_bgp_no_c.svg" alt="Effect of bandwidth on BGP AMF (non-C)" class="plot_non_c" />
<img src="img/experiments/delay/plot_bgp_c.svg" alt="Effect of bandwidth on BGP AMF (C)" class="plot_c" />
</center>
<figcaption>
            <p><span class="label">Fig. 11:</span> When the BGP-based AMF algorithm is used, query evaluation times decrease with increased bandwidth, even for more than 2048kbps,
showing that this algorithm can make better use of higher bandwidths.</p>
          </figcaption>
</figure>

        <figure id="plot_in_vs_out_band">
<center>
<img src="img/experiments/in_vs_out_band/plot_no_c.svg" alt="In-band vs out-band (non-C)" class="plot_non_c" />
<img src="img/experiments/in_vs_out_band/plot_c.svg" alt="In-band vs out-band (C)" class="plot_c" />
</center>
<figcaption>
            <p><span class="label">Fig. 12:</span> Query evaluation times comparing out-of-band and in-band based on different
AMF triple count threshold show no major differences.</p>
          </figcaption>
</figure>

        <h4 class="display-block" id="false-positive-probabilities">False-positive Probabilities</h4>

        <figure id="plot_probabilities">
<center>
<img src="img/experiments/probabilities/plot_no_c.svg" alt="In-band vs out-band (non-C)" class="plot_non_c" />
<img src="img/experiments/probabilities/plot_c.svg" alt="In-band vs out-band (C)" class="plot_c" />
</center>
<figcaption>
            <p><span class="label">Fig. 13:</span> Query evaluation times comparing different false-positive probabilities for AMFs that are generated server-side.
Extremely low and high probabilities show a negative impact.</p>
          </figcaption>
</figure>

        <p><a href="#plot_probabilities">Fig. 13</a> shows that different false-positive probabilities have impact on query evaluation times.
This impact has however only a weak significance (<em>p-value: 0.1840</em>).
On average, a false-positive probability of 1/64 leads to the lowest overall query evaluation times for this experiment.</p>

      </div>
</section>

  <section id="conclusions" inlist="" rel="schema:hasPart" resource="#conclusions">
<div datatype="rdf:HTML" property="schema:description">
        <h2 property="schema:name">Conclusions</h2>

        <p>In this article, we introduced client-side and server-side improvements
to the AMF feature for TPF.
The experimental results show that our client-side algorithms make average query execution more than two times faster than with regular TPF
while only requiring 10% of the number of HTTP requests,
at the cost of less than 10% additional server CPU usage.</p>

        <p>We offer implementations of these algorithms and server enhancements,
which means that they can be used by any of the existing data publishers
that are exposing their data through a TPF interface,
or any client that aims to query from them.</p>

        <p>Hereafter, we conclude our findings with respect to our research questions,
based on the <a href="#evaluation">evaluation</a>,
and we introduce a set of recommendations for data publishers using AMF with TPF.</p>

        <h3 id="research-findings">Research findings</h3>

        <h4 id="bgp-based-algorithms-improve-query-efficiency">BGP-based Algorithms Improve Query Efficiency</h4>

        <p>Results show that our new client-side BGP-based algorithms that use AMF metadata
significantly reduce query evaluation times  (<em><a href="#question-combine">Research Question 1</a></em>).
However, the are a few outliers where our new algorithms perform <em>worse</em> than the triple-based algorithm.
This is because AMFs are sometimes very large,
which has a significant impact on query execution times when they have to be downloaded from the server.
Our results have shown that a heuristic that can decide whether or not to use the BGP-based algorithm can solve this problem,
but further research is needed to come up with a more general heuristic that works in a variety of cases.</p>

        <h4 id="bgp-based-algorithms-postpone-time-to-first-results">BGP-based Algorithms Postpone Time to First Results</h4>

        <p>Even though total query evaluation times for the AMF-aware algorithms are mostly lower,
we observe that the time-until-first-result is mostly higher.
The reason for this is that the BGP-based algorithms tends to use larger AMFs,
which introduces a bottleneck when requesting them over HTTP.
Even though we have this overhead, the gains we get from this are typically worth it,
as results come in much faster once the AMFs have been downloaded.
This finding shows that dynamically switching between different algorithms may be interesting to investigate in future work.
Our bandwidth experiment results confirm this bandwidth bottleneck when downloading large AMFs,
and show that higher bandwidths lead to even more performance gains
for the BGP-level algorithms (<em><a href="#question-bandwidth">Research Question 4</a></em>).
This <em>continuous efficiency</em> can be investigated further in the future
using metrics such as <a property="schema:citation http://purl.org/spar/cito/cites" href="https://iswc2017.semanticweb.org/wp-content/uploads/papers/MainProceedings/383.pdf"><em>diefficiency</em></a> <span class="references">[<a href="#ref-19">19</a>]</span>.</p>

        <h4 id="pre-computation-and-caching-of-amfs-is-essential">Pre-computation and Caching of AMFs is Essential</h4>

        <p>Our results show that AMF-aware querying only has a positive impact on query evaluation times
if the server can deliver AMF filters sufficiently fast (<em><a href="#question-cache">Research Question 2</a></em>)
by for example caching them.
Furthermore, if no cache is active, AMF-aware querying performs <em>worse</em> than non-AMF-aware querying.
Ideally, all AMFs should be pre-computed, but due to the large number of possible triple patterns in a dataset,
this is not feasible.
On the other hand, our results have shown that server-side on the fly creation of AMFs
only starts to have a significant impact for sizes larger than 10.000 (<em><a href="#question-dynamic-restriction">Research Question 3</a></em>).</p>

        <p>On a low-end machine (2,7 GHz Intel Core i5, 8GB RAM), creation of AMFs takes 0.0125 msec per triple,
or 0.125 seconds for AMF creation of size 10.000.
As such, AMFs of size 10.000 or less can be created on the fly with acceptable durations for Web servers
(after which they can still be cached).</p>

        <p><a href="#plot_triple_pattern_counts">Fig. 14</a> shows that there is only a very small number of triple patterns with a very large number of matches.
When setting the WatDiv dataset to a size of 10M triples, there are only 90 triple patterns with a size larger than 10.000.
Setting that size to 100M triples, this number increases to 255, so this is not a linear increase.
Due to this low number of very large patterns,
servers can easily pre-compute these offline before dataset publication time.
Since the WatDiv dataset achieves a high diversity of <a property="schema:citation http://purl.org/spar/cito/cites" href="https://dl.acm.org/citation.cfm?id=1989340"><em>structuredness</em>, it is similar to real-world RDF datasets</a> <span class="references">[<a href="#ref-20">20</a>]</span>.
As such, this behavior can be generalized to other datasets with a similar structuredness.</p>

        <figure id="plot_triple_pattern_counts">
<center>
<img src="img/triple_pattern_counts/plot_counts.svg" alt="Triple pattern counts" class="plot_non_c" />
</center>
<figcaption>
            <p><span class="label">Fig. 14:</span> Logarithmic plot of the number of matches for triple patterns in five datasets of varying sizes,
limited to the 1000 patterns with the most matches.
Triple patterns are sorted by decreasing number of matches.</p>
          </figcaption>
</figure>

        <h4 id="bloom-filters-are-preferred-over-gcs-with-active-cache">Bloom Filters are Preferred over GCS with Active Cache</h4>

        <p>Results show that when AMFs are pre-computed,
Bloom filters achieve faster query evaluation times than GCS (<em><a href="#question-cache">Research Question 2</a></em>).
This is because Bloom filter creation requires less effort client-side than GCS due to the simpler decompression,
at the cost of more server effort.
However, this higher server effort is negligible if AMFs can be pre-computed.
As such, we recommend Bloom filters to always be preferred over GCS, unless AMFs can not be cached.</p>

        <h4 id="a-good-trade-off-between-false-positive-probabilities-and-amf-size">A Good Trade-off Between False-positive Probabilities and AMF Size</h4>

        <p>Lowering the false-positive probability of an AMF increases its size.
As we have seen that larger AMFs have an impact on query evaluation times,
we do not want AMFs to become too large.
On the other hand, we do not want the false-positive probabilities to become too low,
as that leads to more unneeded HTTP requests.
Our results have shown that a probability of 1/64 leads to an optimal balance for our experiments (<em><a href="#question-probabilities">Research Question 5</a></em>).
However, further research is needed to investigate this trade-off for other types of datasets and queries.</p>

        <h3 id="recommendations">Recommendations for Publishers</h3>

        <p>Based on the conclusions of our experimental results,
we derived the following guidelines for publishers who aim to use the AMF feature:</p>

        <ul>
          <li>Enable <strong>HTTP caching</strong> with a tool such as <a href="https://www.nginx.com/">NGINX</a>.</li>
          <li><strong>Pre-compute AMFs</strong> (or at least cache) AMFs of size 10.000 or higher.</li>
          <li>If AMFs can be cached, prefer <strong>Bloom filters</strong> over GCS.</li>
          <li>Use a false-positive <strong>probability of 1/64</strong>.</li>
        </ul>

      </div>
</section>

</main>

<footer><section>
<h2 id="references">References</h2>
<dl class="references">
  <dt id="ref-1">[1]</dt>
  <dd resource="http://link.springer.com/chapter/10.1007/978-3-642-41338-4_18" typeof="schema:Chapter">Buil-Aranda, C., Hogan, A., Umbrich, J., Vandenbussche, P.-Y.: SPARQL Web-Querying Infrastructure: Ready for Action? In: The Semantic Web–ISWC 2013. pp. 277–293 (2013).</dd>
  <dt id="ref-2">[2]</dt>
  <dd resource="https://dx.doi.org/10.1016/j.websem.2016.03.003" typeof="schema:Article">Verborgh, R., Vander Sande, M., Hartig, O., Van Herwegen, J., De Vocht, L., De Meester, B., Haesendonck, G., Colpaert, P.: Triple Pattern Fragments: a Low-cost Knowledge Graph Interface for the Web. Journal of Web Semantics. (2016).</dd>
  <dt id="ref-3">[3]</dt>
  <dd resource="https://dx.doi.org/10.1007/978-3-319-48472-3_48" typeof="schema:Article">Hartig, O., Buil-Aranda, C.: Bindings-Restricted Triple Pattern Fragments. In: Proceedings of the 15th International Conference on Ontologies, DataBases, and Applications of Semantics. pp. 762–779 (2016).</dd>
  <dt id="ref-4">[4]</dt>
  <dd resource="#sage" typeof="schema:Article">Minier, T., Skaf-Molli, H., Molli, P.: SaGe: Web preemption for public SPARQL query services. In: The World Wide Web Conference. pp. 1268–1278 (2019).</dd>
  <dt id="ref-5">[5]</dt>
  <dd resource="#smartkg" typeof="schema:Article">Amr, A., Fernandez Garcia, J.D., Maribel, A., Polleres, A.: SMART-KG: Hybrid Shipping for SPARQL Querying on the Web. (2020).</dd>
  <dt id="ref-6">[6]</dt>
  <dd resource="https://dx.doi.org/10.1109/MIC.2018.032501515" typeof="schema:Article">Verborgh, R., Dumontier, M.: A Web API ecosystem through feature-based reuse. Internet Computing. 22, 29–37 (2018).</dd>
  <dt id="ref-7">[7]</dt>
  <dd resource="http://linkeddatafragments.org/publications/iswc2015-amf.pdf" typeof="schema:Article">Vander Sande, M., Verborgh, R., Van Herwegen, J., Mannens, E., Van de Walle, R.: Opportunistic Linked Data querying through approximate membership metadata. In: International Semantic Web Conference. pp. 92–110. Springer (2015).</dd>
  <dt id="ref-8">[8]</dt>
  <dd resource="http://linkeddatafragments.org/publications/eswc2015.pdf" typeof="schema:Article">Van Herwegen, J., Verborgh, R., Mannens, E., Van de Walle, R.: Query Execution Optimization for Clients of Triple Pattern Fragments. In: The Semantic Web. Latest Advances and New Domains (2015).</dd>
  <dt id="ref-9">[9]</dt>
  <dd resource="http://rubensworks.net/raw/publications/2017/vtpf.pdf" typeof="schema:Article">Taelman, R., Vander Sande, M., Verborgh, R., Mannens, E.: Versioned Triple Pattern Fragments: A Low-cost Linked Data Interface Feature for Web Archives. In: Proceedings of the 3rd Workshop on Managing the Evolution and Preservation of the Data Web (2017).</dd>
  <dt id="ref-10">[10]</dt>
  <dd resource="#tpfusage" typeof="schema:Article">Verborgh, R.: DBpedia’s triple pattern fragments: usage patterns and insights. In: European Semantic Web Conference. pp. 431–442. Springer (2015).</dd>
  <dt id="ref-11">[11]</dt>
  <dd resource="http://crystal.uta.edu/~mcguigan/cse6350/papers/Bloom.pdf" typeof="schema:Article">Bloom, B.H.: Space/time trade-offs in hash coding with allowable errors. Communications of the ACM. 13, 422–426 (1970).</dd>
  <dt id="ref-12">[12]</dt>
  <dd resource="https://www.cs.amherst.edu/~ccmcgeoch/cs34/papers/cacheefficientbloomfilters-jea.pdf" typeof="schema:Article">Putze, F., Sanders, P., Singler, J.: Cache-, hash-, and space-efficient bloom filters. Journal of Experimental Algorithmics (JEA). 14, 4 (2009).</dd>
  <dt id="ref-13">[13]</dt>
  <dd resource="https://ieeexplore.ieee.org/abstract/document/1055357/" typeof="schema:Article">Gallager, R., Van Voorhis, D.: Optimal source codes for geometrically distributed integer alphabets (corresp.). IEEE Transactions on Information theory. (1975).</dd>
  <dt id="ref-14">[14]</dt>
  <dd resource="https://dl.acm.org/citation.cfm?id=2063784" typeof="schema:Article">Huang, H., Liu, C.: Estimating selectivity for joined RDF triple patterns. In: Proceedings of the 20th ACM international conference on Information and knowledge management. pp. 1435–1444. ACM (2011).</dd>
  <dt id="ref-15">[15]</dt>
  <dd resource="https://www.researchgate.net/profile/Thomas_Neumann2/publication/47863714_Scalable_Join_Processing_on_Very_Large_RDF_Graphs/links/00b7d51d1687cae740000000.pdf" typeof="schema:Article">Neumann, T., Weikum, G.: Scalable join processing on very large RDF graphs. In: Proceedings of the 2009 ACM SIGMOD International Conference on Management of data. pp. 627–640. ACM (2009).</dd>
  <dt id="ref-16">[16]</dt>
  <dd resource="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8406674" typeof="schema:Article">Dia, A.F., Aoul, Z.K., Boly, A., Métais, E.: Fast SPARQL join processing between distributed streams and stored RDF graphs using bloom filters. In: 12th International Conference on Research Challenges in Information Science (2018).</dd>
  <dt id="ref-17">[17]</dt>
  <dd resource="https://domino.mpi-inf.mpg.de/intranet/ag5/ag5publ.nsf/0/DAAD136B50B0C0ECC12579E6004D6582/$file/p2-hose.pdf" typeof="schema:Article">Hose, K., Schenkel, R.: Towards benefit-based RDF source selection for SPARQL queries. In: Proceedings of the 4th International Workshop on Semantic Web Information Management. p. 2. ACM (2012).</dd>
  <dt id="ref-18">[18]</dt>
  <dd resource="https://comunica.github.io/Article-ISWC2018-Resource/" typeof="schema:Article">Taelman, R., Van Herwegen, J., Vander Sande, M., Verborgh, R.: Comunica: a Modular SPARQL Query Engine for the Web. In: Proceedings of the 17th International Semantic Web Conference (2018).</dd>
  <dt id="ref-19">[19]</dt>
  <dd resource="https://iswc2017.semanticweb.org/wp-content/uploads/papers/MainProceedings/383.pdf" typeof="schema:Article">Acosta, M., Vidal, M.-E., Sure-Vetter, Y.: Diefficiency metrics: measuring the continuous efficiency of query processing approaches. In: International Semantic Web Conference. pp. 3–19. Springer (2017).</dd>
  <dt id="ref-20">[20]</dt>
  <dd resource="https://dl.acm.org/citation.cfm?id=1989340" typeof="schema:Article">Duan, S., Kementsietsidis, A., Srinivas, K., Udrea, O.: Apples and oranges: a comparison of RDF benchmarks and real RDF datasets. In: Proceedings of the 2011 ACM SIGMOD International Conference on Management of data</dd>
</dl>
</section>
</footer>

</div>



</body>
</html>
